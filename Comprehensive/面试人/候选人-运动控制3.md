
下面给你一套 **专门针对“强化学习 + 全身运动控制”岗位**、并完全结合该候选人履历的**面试提纲（60 分钟）**。  
问题力求“精准击中简历中的能力空白”，既考察基础，又能有效区分“只是复现过论文”和“具备真实运控能力”。

结构如下：  
1）项目深度验证（15 分钟）  
2）强化学习运动控制核心考察（20 分钟）  
3）动力学 / 控制基础（15 分钟）  
4）综合能力与工程落地（10 分钟）

---

# ✅ **一、项目经历深度追问（15 分钟）**

重点：判断是否真正做过 RL 运控，而不是“跑了别人代码”。

---

## **1. IsaacLab 双足 RL 复现中，reward 中哪些项对步态最关键？你是怎么调的？**

**看点：**真正复现过 vs 只调参数  
**优秀回答应包含：**

- base orientation / velocity tracking
    
- foot clearance、swing smoothness
    
- contact consistency（foot velocity @ contact）
    
- torque penalty、collision penalty
    
- action rate penalty 抗抖动
    
- asymmetry 惩罚（简历写到“解决步态不对称”）
    
- explanation：哪些 reward 会引起步态抖动 / 不稳定
    

---

## **2. 你说解决了“足部姿态不合理”，你具体怎么判断、不合理体现在哪？做了哪些修改？**

**考察：**是否理解 foot orientation 影响 CoM 稳定  
**期待回答：**

- foot roll/pitch 过大导致着地冲击
    
- contact phase detect
    
- foot pose tracking reward
    
- 加入 foot orientation regularization
    
- 降低在接触区域的足端速度
    

**危险信号：**只回答“调 reward 就好了”。

---

## **3. 你在 PPO 和 imitation learning 上做了哪些融合？有哪些部分是你自己写的？**

**期待回答：**

- behavior cloning warm start
    
- KL regularization
    
- policy architecture：MLP / GRU
    
- early termination conditions
    
- PD 控制在 action space 的处理
    

**风险点：**

- 如果只说“照着论文跑”，则深度不足。
    

---

## **4. UR5 视觉伺服中，你用 MLP 推图像雅可比，你如何保证稳定性？**

**期待回应：**

- Jacobian smoothness loss
    
- online adaptation
    
- damped pseudo-inverse
    
- redundancy / nullspace 控制
    

（重点看：他是否真正知道视觉伺服中 Jacobian 不稳定的后果）

---

# 🟦 **二、强化学习运动控制核心问题（20 分钟）**

这部分非常重要，用于判断候选人是否具有 _从复现→真正做 RL 运控_ 的潜力。

---

## **5. 强化学习在双足机器人上的主要困难是什么？你遇到过哪些？**

**标准要点：**

- 迟滞 + 延迟（actuator latency）
    
- contact dynamics mismatch（Sim2Real gap）
    
- 性能要求高时 reward shaping 难
    
- Asymmetric gait vs symmetric gait
    
- 高维度 action space（全身）
    
- Observability 问题（state 不够）
    

---

## **6. PPO 为什么适合控制任务？它的核心机制是什么？说一下 “clip” 的物理意义。**

**期望：**

- trust region 的近似
    
- 防止 policy 更新过大导致 collapse
    
- clipped objective 限制梯度
    
- 作用：鲁棒性更强、训练稳定
    

**风险点：**  
只会背“PPO 是一个策略梯度方法”，那说明 RL 理解薄弱。

---

## **7. 你在真实机器人部署 RL 策略时，会遇到哪些抖动问题？如何解决？**

**期望回答：**

- action rate 过大 → filtered action
    
- torque spikes
    
- sensor noise
    
- 足端 contact 噪声
    
- 用：LPF、torque smoothing、domain randomization
    
- PD stabilization + policy blending
    

问这个题是为了判断候选人是否知道真人形机器人执行 RL 的工程痛点。

---

## **8. 如果你要做一个“模仿学习 + RL”用于我们全身控制，你会怎样设计 pipeline？**

**优秀回答：**  
1）从动捕收集数据  
2）Preprocess（normalize、phase、foot contact、retarget）  
3）训练一个 latent policy（VAE/Amp）  
4）RL fine-tune（task reward + style reward）  
5）constraint：joint limit、contact consistency  
6）deploy with PD

（如果他能说 AMP → 加分）

---

# 🟩 **三、机器人动力学 / 控制基础（15 分钟）**

他的本科和实习中涉及 MPC / OCS2，所以可以深挖：

---

## **9. 你说在四足机器人上做过 OCS2，你能说清楚：MPC 里 cost 和 constraint 各包含什么吗？**

**期望：**

- cost：tracking（CoM/foot）、smoothness、torque
    
- constraint：动力学、接触力、摩擦锥、foot placement
    
- OCS2 使用 SQP → alternating linearization
    

**风险点：**  
只回答“cost → tracking，constraint → 限制”= 深度不够。

---

## **10. 请解释：`τ = M(q)q¨ + C(q, q˙) + g(q)` 对强化学习有什么意义？**

**优秀点：**

- RL 输出一般不是 torque，而是 PD / target position
    
- 策略需要隐式适应 M、C、g
    
- 这导致 sim2real gap
    
- 动力学漂移的应对方式：domain randomization / system ID
    

---

## **11. 你能解释一下什么是 Jacobian 奇异性吗？在人形机器人中会如何影响 RL？**

**期望点：**

- rank deficiency
    
- foot/hand orientation 不可达
    
- near singularity → torque amplification
    
- RL 可能学到危险策略（如腿伸直）
    
- 需要 regularization、joint limit、reward shaping 避免
    

---

## **12. 你熟悉的 MPC 与 RL 在控制双足机器人时的互补关系是什么？**

**期待回答：**

- MPC：高层/预测/coarse control，保持稳定
    
- RL：生成自然动作/补偿动力学细节
    
- 典型结构：MPC plan → RL refine → WBC torque
    

如果能提到“model-based + model-free hybrid control”，说明水平不错。

---

# 🟧 **四、综合能力与工程落地（10 分钟）**

让你判断 TA 的工程能力是否适合实战。

---

## **13. 在 ROS 或真实机器人调试中，你遇到过最棘手的 bug？怎么定位？**

**想听到：**

- latency
    
- TF 错乱
    
- contact 判断误差
    
- sensor drift
    
- MPC 和执行器频率 mismatch
    
- log 记录、rviz 可视化、状态重放（debug pipeline）
    

---

## **14. 你复现 RL 论文时，最大的问题是什么？你做了什么工具提高调试效率？**

**期望：**

- reward 可视化
    
- tensorboard
    
- log replay
    
- policy evaluation script
    
- hyperparameter sweep
    

---

## **15. 你打算如何将你现在的研究能力迁移到我们全身运动控制团队？**

你希望听到：

- “我能从视觉伺服 → 全身控制迁移，掌握了 Jacobian、控制理论”
    
- “我知道从模拟到实机需要 actuator model、latency compensation”
    
- “我做过 RL reward shaping，有能力训练复杂策略”
    

---

# 🟦 **这套 60 分钟面试能测出什么？**

- RL 理解深度（是否仅复现过）
    
- 对运动控制真实工程涵义的理解
    
- 对动力学基础的掌握
    
- 是否具有双足/人形机器人可迁移性
    
- Debug 能力
    
- 是否适合做我们部门的任务（全身运动控制 + RL）
    

---

如果你需要，我可以继续为你：  
🔥 给出 **每题的评分标准（优秀/合格/不合格）**  
🔥 设计 **更高阶的 AMP / Whole-Body RL / MPC 混合控制专项题**  
🔥 给你一份 **最终评价报告模板（适用于 HR + 技术评审）**

你需要吗？


