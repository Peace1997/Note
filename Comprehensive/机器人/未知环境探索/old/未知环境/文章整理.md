# 文章整理

- 单智能体方法
- 多智能体传统方法
- 多智能体强化学习方法
- 多智能体目标导航方法



## 1. 单智能体方法：

- Yamauchi B. A frontier-based approach for autonomous exploration[C]//Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97.'Towards New Computational Principles for Robotics and Automation'. IEEE, 1997: 146-151.
- **Li H, Zhang Q, Zhao D. Deep reinforcement learning-based automatic exploration for navigation in unknown environment[J]. IEEE transactions on neural networks and learning systems, 2019, 31(6): 2064-2076.**
- Zhu D, Li T, Ho D, et al. Deep reinforcement learning supervised autonomous exploration in office environments[C]//2018 IEEE international conference on robotics and automation (ICRA). IEEE, 2018: 7548-7555.

- Botteghi N, Schulte R, Sirmacek B, et al. Curiosity-Driven Reinforcement Learning Agent for Mapping Unknown Indoor Environments[J]. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2021, 1: 129-136.

​				

## 2. 多智能体传统方法

- **Burgard W, Moors M, Stachniss C, et al. Coordinated multi-robot exploration[J]. IEEE Transactions on robotics, 2005, 21(3): 376-386.**

- Wurm K M, Stachniss C, Burgard W. Coordinated multi-robot exploration using a segmentation of the environment[C]//2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2008: 1160-1165.

- **Hu J, Niu H, Carrasco J, et al. Voronoi-based multi-robot autonomous exploration in unknown environments via deep reinforcement learning[J]. IEEE Transactions on Vehicular Technology, 2020, 69(12): 14413-14423.**

- Simmons R, Apfelbaum D, Burgard W, et al. Coordination for multi-robot exploration and mapping[C]//Aaai/Iaai. 2000: 852-858.

- Albina K, Lee S G. Hybrid stochastic exploration using grey wolf optimizer and coordinated multi-robot exploration algorithms[J]. IEEE Access, 2019, 7: 14246-14255.

- Wang D, Wang H, Liu L. Unknown environment exploration of multi-robot system with the FORDPSO[J]. Swarm and Evolutionary Computation, 2016, 26: 157-174.

- de Almeida J P L S, Nakashima R T, Neves-Jr F, et al. Bio-inspired on-line path planner for cooperative exploration of unknown environment by a Multi-Robot System[J]. Robotics and Autonomous Systems, 2019, 112: 32-48.

- Dong H, Jincheng Y, Xu Y, et al. MR-GMMapping: Communication Efficient Multi-Robot Mapping System via Gaussian Mixture Model[J]. IEEE Robotics and Automation Letters, 2022.

- Yu J, Tong J, Xu Y, et al. Smmr-explore: Submap-based multi-robot exploration system with multi-robot multi-target potential field exploration method[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 8779-8785.

- Dai X, Jiang L, Zhao Y. Cooperative exploration based on supervisory control of multi-robot systems[J]. Applied Intelligence, 2016, 45(1): 18-29.

- Matignon L, Jeanpierre L, Mouaddib A I. Coordinated multi-robot exploration under communication constraints using decentralized markov decision processes[C]//Twenty-sixth AAAI conference on artificial intelligence. 2012.

- Smith A J, Hollinger G A. Distributed inference-based multi-robot exploration[J]. Autonomous Robots, 2018, 42(8): 1651-1668.

  





## 3. 多智能体强化学习方法

- Tai L, Paolo G, Liu M. Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation[C]//2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2017: 31-36.
- He D, Feng D, Jia H, et al. Decentralized Exploration of a Structured Environment Based on Multi-agent Deep Reinforcement Learning[C]//2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS). IEEE, 2020: 172-179.
- Chen Z, Subagdja B, Tan A H. End-to-end deep reinforcement learning for multi-agent collaborative exploration[C]//2019 IEEE International Conference on Agents (ICA). IEEE, 2019: 99-102.
- Luo T, Subagdja B, Wang D, et al. Multi-agent collaborative exploration through graph-based deep reinforcement learning[C]//2019 IEEE International Conference on Agents (ICA). IEEE, 2019: 2-7.
- Geng M, Zhou X, Ding B, et al. Learning to cooperate in decentralized multi-robot exploration of dynamic environments[C]//International Conference on Neural Information Processing. Springer, Cham, 2018: 40-51.
- Geng M, Zhou X, Ding B, et al. Learning to cooperate in decentralized multi-robot exploration of dynamic environments[C]//International Conference on Neural Information Processing. Springer, Cham, 2018: 40-51.



## 4. 多智能体目标导航方法

- Han R, Chen S, Hao Q. Cooperative multi-robot navigation in dynamic environment with deep reinforcement learning[C]//2020 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2020: 448-454.
- Jin Y, Zhang Y, Yuan J, et al. Efficient multi-agent cooperative navigation in unknown environments with interlaced deep reinforcement learning[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 2897-2901.
- Lin J, Yang X, Zheng P, et al. Connectivity guaranteed multi-robot navigation via deep reinforcement learning[C]//Conference on Robot Learning. PMLR, 2020: 661-670.



## 5. 多智能体探索性能基准

- Yan Z, Fabresse L, Laval J, et al. Metrics for performance benchmarking of multi-robot exploration[C]//2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2015: 3407-3414.







多智能体：

- 
- Wang D, Wang H, Liu L. Unknown environment exploration of multi-robot system with the FORDPSO[J]. Swarm and Evolutionary Computation, 2016, 26: 157-174.   
- de Almeida J P L S, Nakashima R T, Neves-Jr F, et al. Bio-inspired on-line path planner for cooperative exploration of unknown environment by a Multi-Robot System[J]. Robotics and Autonomous Systems, 2019, 112: 32-48.    
- Yu J, Tong J, Xu Y, et al. Smmr-explore: Submap-based multi-robot exploration system with multi-robot multi-target potential field exploration method[C]//2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021: 8779-8785.
- Simmons R, Apfelbaum D, Burgard W, et al. Coordination for multi-robot exploration and mapping[C]//Aaai/Iaai. 2000: 852-858.
- Burgard W, Moors M, Stachniss C, et al. Coordinated multi-robot exploration[J]. IEEE Transactions on robotics, 2005, 21(3): 376-386.
- Wurm K M, Stachniss C, Burgard W. Coordinated multi-robot exploration using a segmentation of the environment[C]//2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2008: 1160-1165.
- Dai X, Jiang L, Zhao Y. Cooperative exploration based on supervisory control of multi-robot systems[J]. Applied Intelligence, 2016, 45(1): 18-29.
- Smith A J, Hollinger G A. Distributed inference-based multi-robot exploration[J]. Autonomous Robots, 2018, 42(8): 1651-1668.
- Han R, Chen S, Hao Q. Cooperative multi-robot navigation in dynamic environment with deep reinforcement learning[C]//2020 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2020: 448-454.
- Amigoni F, Banfi J, Basilico N. Multirobot exploration of communication-restricted environments: A survey[J]. IEEE Intelligent Systems, 2017, 32(6): 48-57.
- Matignon L, Jeanpierre L, Mouaddib A I. Coordinated multi-robot exploration under communication constraints using decentralized markov decision processes[C]//Twenty-sixth AAAI conference on artificial intelligence. 2012.
- Lin J, Yang X, Zheng P, et al. Connectivity guaranteed multi-robot navigation via deep reinforcement learning[C]//Conference on Robot Learning. PMLR, 2020: 661-670.

- Dong H, Jincheng Y, Xu Y, et al. MR-GMMapping: Communication Efficient Multi-Robot Mapping System via Gaussian Mixture Model[J]. IEEE Robotics and Automation Letters, 2022.



评价指标：

- Yan Z, Fabresse L, Laval J, et al. Metrics for performance benchmarking of multi-robot exploration[C]//2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2015: 3407-3414.



多智能体目标搜索：









未找到

- Bayesian reinforcement learning for multi-robot decentralized patrolling in uncertain environ- ments
- Communication-Efficient Planning and Mapping for Multi-Robot Exploration in Large Environments





设置地图，重新开始训练，先从简单地图开始。



基于**分区**的多智能体强化学习探索