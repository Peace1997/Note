# 一、 综合问题


## 实习的难点
- 【项目整体把握】做项目的整体过程，对一个项目，通常调研不是很充分，通常就是边做边规划，而在工作中通常需要有一个完整的调研，然后规划出几个月的任务安排，任务安排到天，这需要对对整个项目有一个清晰的认知。 
- 【调研完整度】学校时通常只需要调研当前学术论文，而且有时调研不够充分；这里调研时，得需要对当前国内外整个行业进展调研，他们完成了哪些内容，达成了哪些指标，我们要做的内容是什么，达成怎样的治标，为什么要这样做，不这样做行不行，多久能做出来。
- 【项目难点】项目开始时的难点是，对一个问题进行数学建模，转换成强化学习的模式。搭建整个系统框架。
- 【任务汇总】任务汇报的时候，不同于学校的一些技术、组会、答辩汇报，通常是面向技术的汇报；对领导汇报时，内容要充实，汇报要抓好重点，需要更加简洁、清晰、明了的解释你在做的东西或你将要去的东西，需要更好的总结，不仅面向技术，还要有整体任务的把握。


## 优缺点

【优点】
- 执行力强、学习能力强，能够按时有效的完成导师、领导布置的任务
- 具备较强独立解决问题的能力、同时也具备良好的团队协作能力
- 对新技术有持续的热情，乐于去学习相应领域最新的研究成果。
【缺点】
- 目前主要是在学校里参与科研项目，没有充足的实际工作经验。
- 强化学习通常是在仿真环境下实现的，缺少一些真机的实践经验
- 所具备的专业基础和专业能力相对比较基础，还需要在实践和日后工作中不断学习和总结。

## 你做整个项目的流程是怎么样的
- 【调研】；调研当前国内外研究现状，并对它们实现的效果及优缺点进行总结，复现已有的代码。
- 【任务方案】根据项目要求，写一个基础的项目实现方案，明确任务目标，选择合适算法，明确算法的输入输出，接下来去选择合适的仿真平台。
- 【环境搭建】完成仿真平台的搭建，测试是否可以得到我们想要的数据，测试是否可以实现交互，编写合适的算法，并测试模型是否可以正常运行，
- 【算法交互】完成算法与仿真环境的交互，在交互过程中，打印奖励函数、损失函数，根据反馈的信息不断调参。
- 【验证测试】设计不同的测试方案，对算法进行测试验证。

## 应聘单位的了解 & 应聘岗位的职责和理解

***应聘单位的了解***
我有简单调研了智源团队相关的一些研究进展（悟道大模型、天演生命模拟工程、九鼎智算平台、FlagAI开源平台），也有了解包括智源社区和智源大会分享的内容，所研究的内容和交流的技术都是当前世界技术前沿。研究院的文化的是目标导向、自由探索的，不论资排辈，推崇代表作文化。

有关具身智能
具身智能（embodied intelligence）是指人工智能系统在有形机械身体上实现的智能。具身智能涉及到机器人、机器人手臂、机器人车辆等有形机械身体，以及这些身体上的传感器、执行器等组件。

具身智能能够使人工智能系统在真实环境中实现观察、感知、决策和行动等能力。具身智能的应用领域广泛，包括机器人导航、机器人仿生、机器人工业自动化等。

具身智能是人工智能的一个重要领域，与无形智能（non-embodied intelligence）相对。无形智能是指人工智能系统在软件或硬件设备上实现的智能，例如软件机器学习系统或智能手机。

***应聘岗位的职责和理解***
我投递岗位所在的团队是具身智能研究中心，结合二面老师的介绍和我对岗位的理解，我的主要职责有三个：
- 主要的研究方向是将强化学习应用在真机机械臂中，设计安全有效的可直接应用的算法方案；
- 辅助相关的博士团队，做一些实验方案的设计和验证；
- 负责硬件、真机设备的维护和测试

其中最核心的要点就是，高效按时完成的分配的完成所分配的任务。

## 未来的工作计划

- 首先熟悉研究团队项目，确定研究目标，尽快参与到项目研究中，与团队成员积极有效的交流合作。主动高效的完成分配的任务。
- 然后不断提升自身科研能力，了解整个项目的机制流程，全方面的去提升自己（知识技能、分析总结能力、语言表达），从而负责整个项目的研发。从而可以具备独当一面的能力。

## 工作岗位更看重哪些因素

- 【工作环境、科研氛围】：良好共享的学术氛围，团队中的大家以相同的目标导向，每个人都积极主动的去探索去学习相应领域的知识，集中力量完成一个有意义的工作
- 【研究方向】：我研究生期间的研究方向是多智能体深度强化学习方向和机器人决策规划方向，我其实更想在这个领域去做下去，可能研究生期间因为一些因素在仿真环境下实现的多一些，我期望未来可以设计一些可以在真机上可以直接应用的算法模型，去实现应用的落地。
- 【工资待遇】：合理的薪资范畴和福利待遇的政策。

### 反问环节

- 这个岗位我需要提前去掌握的技能或算法有哪些？
- （具身智能研究中心）的人员组成
- 对新员工的培养体系
- 福利待遇
	- 工资的构成
	- 保险和公积金的缴纳比例
	- 福利待遇情况，包括交通补、住房补、饭补等等
	- 上班时间
	- 试用期的时间，工资情况（工资和社保）、考核方式


## 调参技巧

- 首先通过TensorBoard或Wandb对奖励和回报、损失函数的曲线进行打印。
- 整个调参过程主要分为两个阶段，粗调和细调，粗调尽量多尝试几组超参数的组合，增加探索，通过粗调确定几个核心的参数的大体范围,通过粗调可以大致了解各个超参数与奖励之间的隐式关系；细调过程，就根据超参数之间的相互影响关系，不断的精确超参数的值。我通常会绘制一个超参数与奖励之间正负关联图，随着不断修改超参数的大小，观察
- 并行化训练，同时训练多个智能体超参数的选择可以不用偏保守，尽可能多的探索一些运动轨迹，从而可以更好的跳出局部最优解，加速收敛。



岗位职责：

1. 参与机器人运动操控及人机交互的相关研发，搭建智能机器人系统；

2. 设计、维护、实现及测试机器人视觉导航、运动规划、操控等算法；

3. 设计量化评估体系来衡量算法的性能，据此改进算法并整合进系统中；

4. 与其他机器人工程师、机器视觉工程师、项目经理及外部合作商协作，参与算法的部署；

5. 参与研究中心项目，发表研究成果，给团队注入新的理论观点。

任职要求：

1.计算机科学、机器人学、工程学或其他相关领域的硕士及以上学历

2.具备在真实机器人（机械臂、灵巧手、二足、四足、轮式机器人、无人机等）上真机实验的丰富经历，熟悉ROS系统

3.具备以下至少两个领域相关的研究或工作经历：a) **基于深度学习或强化学习的机器人技能学习**， b) 基于优化的运动规划和控制，c) **机器人物理仿真**，d）三维视觉，e) 触觉感知，f) **多机器人协同控制**

4.具备一定的软件工程能力，熟练使用 C++ /Python，及 Linux 操作系统
5.具备软件开发相关经历，熟悉代码文档、单元测试、版本控制等基本操作，并熟练使用 Git, CMake 等软件工程相关工具
6. 能够在一个高效率团队中出色发挥自身能力，且具备有效的沟通技巧



# 二、算法知识

### 强化学习介绍

**简介**：
强化学习通常处理的是序列决策问题，它既没有非常准确的监督信号，也不完全是无监督地发现数据中潜在结构，它通过不断与环境交互去学习一系列的决策，使得模型最终能在环境中获得最大的收益。强化学习与深度学习相结合，更好地增强智能体决策能力，

强化学习能够让机器在复杂环境中自主学习和做出决策，其中机器通过不断尝试和学习来解决问题。这种学习方式与人类的学习方式很相似，

**应用**：
目前强化学习主要广泛应用场景是游戏和机器人，在其他领域也有落地应用，例如推荐系统、金融交易、无人驾驶、 交通控制、自动调参等需要决策的经常。

**问题与挑战**：
- 样本利用率低
- 奖赏函数难以设计和推广
- 实验效果难以复现

**潜力方向**：
- 提出新的有模型的算法，以及尝试搜索与监督的方法，以提升样本的利用效率；
- 迁移学习、元学习、引入 DRL 中，适用多个任务，利用之前任务经验，加速训练，快速适应新任务。
- 模仿学习、分层强化学习，组合多个子任务形成有效的全局策略，加入人类经验，使得模型更可控。
- 将博弈论和多智能体引入 DRL，以适应真实环境中更加复杂的问题。


**强化学习在推荐、广告中的应用？**

购物想法是很容易改变的。假设用户在购物平台停留时间越长，则有可能消费的话，
总体上：监督学习可能希望推荐的每一个商品都停留时间长一点，通过贪婪思想，则整体停留的时间就多一些；强化学习优化目标关注的是整个停留时间，可能有些推荐的商品用户很快划走了，但是最终浏览的累积的时间变长了。所有优化目标就需要去设计相应的状态、动作、奖励。


**强化学习在物流调度中的应用？**

*强化学习与调度：*  即时物流调度系统

目标：最小化

MDP 过程建模：

状态：任务数量、平均任务时间、待决策的任务数量、可用车辆的信息
动作：选择一个车辆
奖励：任务解决的数量、时间、每执行一步的负奖励



### 什么是集成学习？

集成学习算法本身不算一种单独的机器学习算法，而是通过多个简单学习器构成一个强大的学习器。集百家之所长，能在机器学习算法中拥有较高的准确率，不足之处就是模型的训练过程可能比较复杂，效率不是很高。

目前常见的集成学习算法主要有 2 种：
- 基于 **样本集重采样**（Bagging）（自助重采样） 的算法：随机森林
> 由多个决策树组合而成的模型。

- 基于 **提升**（Boosting）思想的算法：Adaboost、GBDT、XGBOOST、梯度提升树 
>通过组合多个弱学习器得到性能良好的强学习器。对于一个复杂任务，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。

### model. train () 和 model. eval () 用法和区别 ？ 

Pytorch下：
- `model.train ()` 的作用是启用 Batch Normalization 和 Dropout，用于训练阶段。
- `model.eval ()` 的作用是不启用 Batch Normalization 和 Dropout ，用于测试阶段。
	此时 pytorch 会自动把 BN 和 DropOut 固定住，不会取平均，而是用训练好的值。不然的话，一旦 test 的 batch_size 过小，很容易就会因 BN 层导致模型 performance 损失较大；
- `torch.no_grad()` 也是用于测试阶段，用于关闭梯度计算，节省 eval 的时间。

只进行 inference 时，model. eval () 是必须使用的，否则会影响结果准确性。 而 torch. no_grad () 并不是强制的，只影响运行效率。


### 梯度消失和梯度爆炸？

链式法则计算梯度时，下层梯度计算小于 1，经过层层累积，上层梯度越来越小，即上层权重更新速率低于下层权重更新速率，导致梯度消失，梯度爆炸则是上层权重更新速率高于下层权重更新速率。
产生原因：层数过多，激活函数不正确
解决：选择合适激活函数，BN/LN
[[梯度消失 & 梯度爆炸]]

### 过拟合现象产生的原因及解决



### BN 和 LN 的区别？

都是用于解决 内部协变量偏移问题，解决梯度消失和过拟合

BN：针对不同样本的同一特征（维度）数据，进行归一化，考虑所有样本的同一维度，因此比较适合大batch-size，而且数据分布比较接近的，不适用于动态的网络结构 和 RNN 网络。
LN：针对同一样本的不同特征数据进行归一化，因为LN考虑单个样本所有特征，因此适合用于NLP任务中，

### 什么是 xgboost 算法



# 三、基础知识

### TCP 和 UDP
1、基于连接与无连接；
2、对系统资源的要求（TCP较多，UDP少）；
3、UDP程序结构较简单；
4、流模式与数据报模式 ；
5、TCP保证数据正确性，UDP可能丢包；
6、TCP 保证数据顺序，UDP 不保证。

### 字典、哈希表、红黑树 
字典由哈希表实现，哈希表是由 数组+链表+红黑树的形式的
散列表（Hash table，也叫哈希表），是根据关键码值(Key)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做**散列函数**，存放记录的数组叫做**散列表**。

哈希表的数据结构
```Python
class HashTable:
    def __init__(self, size):
	    # 使用list数据结构作为哈希表元素保存方法
        self.elem = [None for i in range(size)]  
        self.count = size  # 最大表长

    def hash(self, key):
	    # 散列函数采用除留余数法
        return key % self.count  

    def insert_hash(self, key, value):
        """插入关键字到哈希表内"""
        address = self.hash(key)  # 求散列地址
        while self.elem[address]:  # 当前位置已经有数据了，发生冲突。
            address = (address + 1) % self.count  # 线性探测下一地址是否可用
        self.elem[address] = value  # 没有冲突则直接保存。

    def search_hash(self, key):
        """查找关键字，返回布尔值"""
        star = address = self.hash(key)
        while self.elem[address] != key:
            address = (address + 1) % self.count
            if not self.elem[address] or address == star:  
            # 说明没找到或者循环到了开始的位置
                return False
        return True
```

大体流程：
- **定位**；确定 key 在数组中的对应位置；计算 key 值对应的 hashcode；再对该 hashcode 取一次 hash, 该值用来定位要将这个元素存放到数组中的什么位置。若不同key值对应不同散列地址（存储位置称散列地址），则直接存储即可，
- **冲突解决**：而不同的 key 值可能得到同一散列地址，这种现象称为冲突。如果冲突，则首先判断 value 值是否相同，如果两者相等则直接覆盖，如果不等则在原元素下面使用**链表**的结构存储该元素。
- 数组 + （链表/红黑树）：因为链表中元素太多的时候会影响查找效率，所以当链表的元素个数达到8并且数组长度超过64的时候使用链表存储就转变成了使用红黑树存储，原因就是**红黑树是平衡二叉树（自平衡二叉查找树）**，在查找性能方面比链表要高。
![](HashMap.png)
参考
- https://zhuanlan.zhihu.com/p/79507868
- https://www.jianshu.com/p/d04edc8aaf0f
- http://static.kancloud.cn/alex_wsc/java_source/1852265

### 多线程和多进程的区别？

线程是一个轻量级的子进程，是最小的处理单元，一个进程由多个线程组成；

线程之间共享进程的数据，共享容易，同步难
进程之间相互独立，同步容易，共享难，共享需要 IPC。

进程间通信（IPC）的方式：
- 消息队列：在内核中创建一个队列，队列中每个元素就是一个数据报，不同进程可以通过这个句柄去访问这个队列；消息队列独立于发送与接受进程，可以通过顺序和消息类型读取，也可通过 FIFO 读取；消息队列可以实现双向通信。
- 共享内存：将同一块物理内存映射到不同的进程的虚拟地址空间中，实现不同进程对同一资源的共享。不需要从用户态的频繁切换和拷贝数据，直接从内存读取就可，共享内存是临界资源，操作时必须保证原子性，使用信号量和互斥锁都可以




##  运动学与动力学

 ***1. 运动学（ Dynamics）***
研究的是运动本身，主要是表述物体的速度、加速度和空间位置这几个量之间的大小和方向关系。单纯的运动学研究不涉及物体的质量，也就不涉及到力；经常将物体抽象为质点或某个几何形状，研究特征点之间的速度、加速度、相对位置关系。

**正运动学**：指的是已知关节空间变量关节角或角速度，求取操作空间的位置或速度；
**逆运动学**：是指已知操作空间的位姿或速度，求取关节空间的关节角或关节速度。

***2. 动力学（Kinematics）***
考虑了物体的质量，引入了力和能量，也就是研究物体运动及运动的原因。那么什么时候用运动学，什么时候用动力学。

**正动力学**：已知机器人的关节驱动力矩和上一时刻的运动状态（角度和角速度），计算得到机器人下一时刻的运动加速度，再积分得到速度和角度；
**逆动力学**：已知某一时刻机器人各关节的位置 、关节速度以及关节加速度，求此时施加在机器人各杆件上的驱动力（力矩）

> 逆动力学可以利用牛顿欧拉(Newton-Euler)方程来求解，也可以利用拉格朗日(Lagrange)方程来求解

***3. 运动学与动力学区别***

运动学主要讲运动本身， 动力学主要讲力与运动关系。
运动学通常描述机器人末端和各个关节位置的几何关系，动力学描述的是关节位置和力矩之间的力学关系。

运动学一般是做轨迹规划，生成各个关节的目标轨迹，再通过控制算法，使机器人追踪目标轨迹；而控制算法中为了实现更好地效果，需要考虑机器人的动力学模型，并加入动力学步长。

个人总结，当我们设计某个机器初期，研究其关键零部件的运动轨迹、速度使其满足相应要求时，可以用运动学就可以；当研究如何使机器按照相应速度、加速度平稳的运行起来，涉及到控制时，就需要动力学分析。


## 自动驾驶概述

基于我此前的调研，自动驾驶主要分为：感知定位、决策规划、控制执行。
自动驾驶一般指车辆利用车载传感器来感知车辆周围的环境，根据感知获得道路、车辆位置和障碍物信息，决定驾驶行为、路径规划、速度规划等问题，控制车辆的转向和速度，从而使车辆能够安全、可靠、舒适地在道路上行驶。

**感知定位**：分为环境感知和车辆运动感知，通过内部传传感器和外部传感器获取自身状态（定位）及周边环境信息。
**决策规划**：决策体系通过各部分之间的相互关系和功能分配，决定了车辆的安全行驶模式；规划部分用以生成安全、实时的无碰撞轨迹。
**控制执行**：根据决策规划的轨迹目标，控制车辆的油门、刹车（纵向控制）和转向（横向控制）等驾驶动作。















%%面试官您好，我是来自浙江理工大学，计算机技术专业的硕士马佩鑫 ，很高兴能参加此次（云创智行）面试，我面试的岗位是决策规划算法工程师，我研究生期间主要的研究方向是多智能体深度强化学习方向和机器人决策规划方向，在做未知环境下多机器人的自主探索、自主导航，都有应用决策规划分层控制模块，在中国空间技术研究院（航天五院）杭州中心实习期间，独立负责将强化学习应用在四足机器人行走的运动控制上，了解到咱们这边是以无人环卫为切入场景，以最终实现智慧城市整体解决方案为导向，我认为我当前的研究方向以及未来职业规划和公司是相契合的，很期待加入咱们这边的研究团队，以上是我的自我介绍情况。%%



%%面试官您好，我是来自浙江理工大学，计算机技术专业的硕士马佩鑫 ，很高兴能参加此次（ 真机智能）面试，我面试的岗位是 算法工程师，我研究生期间主要的研究方向是多智能体深度强化学习方向和机器人决策规划方向，在做未知环境下多机器人的自主探索、自主导航，都有涉及 的相关任务，在中国空间技术研究院（航天五院）杭州中心实习期间，岗位方向是机器人运动控制算法，独立负责将强化学习应用在四足机器人行走的运动控制上，为日后登月行走和最后一公里配送做预研，了解到咱们公司主做的产品是户内外通用小型移动机器人（三驾马车），我认为我当前的研究方向以及未来职业规划和公司是相契合的，很期待加入咱们这边的研究团队，以上是我的自我介绍情况。%%



%%面试官您好，我是来自浙江理工大学，计算机技术专业的硕士马佩鑫 ，很高兴能参加此次（真机智能）面试，我面试的岗位是运动规划与控制算法工程师，我研究生期间主要的研究方向是多智能体深度强化学习方向和机器人决策规划方向，在做未知环境下多机器人的自主探索、自主导航，都涉及决策-规划-控制的相关任务，在中国空间技术研究院（航天五院）杭州中心实习期间，岗位方向是机器人运动控制算法，独立负责将强化学习应用在四足机器人行走的运动控制上，为日后登月行走和最后一公里配送做预研，了解到咱们公司主做的产品是户内外通用小型移动机器人（三驾马车），我认为我当前的研究方向以及未来职业规划和公司是相契合的，很期待加入咱们这边的研究团队，以上是我的自我介绍情况。
>真机「青道夫」商用清洁机器人、真机「小黄马」无人配送机器人、真机「青翼蝠」商用巡控机器人

运动规划与控制算法部门人员组成以及新员工的培训
提前需要掌握的能力%%


%%面试官您好，我是来自浙江理工大学，计算机技术专业的硕士马佩鑫 ，很高兴能参加此次（ 顺丰同城）面试，我面试的岗位是机器学习算法工程师，我研究生期间主要的研究方向是多智能体深度强化学习方向和机器人决策规划方向，基于深度强化学习，有做过未知环境下多机器人的自主探索、自主导航，在中国空间技术研究院（航天五院）杭州中心实习期间，独立负责将强化学习应用在四足机器人行走的运动控制上。了解常用的机器学习算法，也与其他专业（交通、土木）做过交叉融合的项目, 有粒子群算法和 Kmeans 算法应用经验，我未来的职业规划也是希望通过机器学习来实现一些智能决策，以上是我的自我介绍情况。%%