
**自我介绍：**

面试官您好，我是来自浙江理工大学，计算机技术专业的硕士马佩鑫 ，很高兴能参加此次（ 顺丰同城）面试，我面试的岗位是机器学习算法工程师，我研究生期间主要的研究方向是多智能体深度强化学习方向和机器人决策规划方向，基于深度强化学习，有做过未知环境下多机器人的自主探索、自主导航，在中国空间技术研究院（航天五院）杭州中心实习期间，独立负责将强化学习应用在四足机器人行走的运动控制上。了解常用的机器学习算法，也与其他专业（交通、土木）做过交叉融合的项目, 有粒子群算法和 Kmeans 算法应用经验，我未来的职业规划也是希望通过机器学习来实现一些智能决策，以上是我的自我介绍情况。


# 1. 基础问题

## 强化学习
**简介**：
强化学习通常处理的是序列决策问题，它既没有非常准确的监督信号，也不完全是无监督地发现数据中潜在结构，它通过不断与环境交互去学习一系列的决策，使得模型最终能在环境中获得最大的收益。强化学习与深度学习相结合，更好地增强智能体决策能力，
**应用**：
目前强化学习主要广泛应用场景是游戏和机器人，在其他领域也有落地应用，例如推荐系统、金融交易、无人驾驶、 交通控制、自动调参等需要决策的经常。
**问题与挑战**：
- 样本利用率低
- 奖赏函数难以设计和推广
- 实验效果难以复现
**潜力方向**：
- 提出新的有模型的算法，以及尝试搜索与监督的方法，以提升样本的利用效率；
- 迁移学习、元学习、引入 DRL 中，适用多个任务，利用之前任务经验，加速训练，快速适应新任务。
- 模仿学习、分层强化学习，组合多个子任务形成有效的全局策略，加入人类经验，使得模型更可控。
- 将博弈论和多智能体引入 DRL，以适应真实环境中更加复杂的问题。

## 什么是集成学习？
集成学习算法本身不算一种单独的机器学习算法，而是通过多个简单学习器构成一个强大的学习器。集百家之所长，能在机器学习算法中拥有较高的准确率，不足之处就是模型的训练过程可能比较复杂，效率不是很高。目前常见的集成学习算法主要有 2 种：

- 基于 **样本集重采样**（Bagging）（自助重采样） 的算法：随机森林
> 由多个决策树组合而成的模型。
- 基于 **提升**（Boosting）思想的算法：Adaboost、GBDT、XGBOOST、梯度提升树 
>通过组合多个弱学习器得到性能良好的强学习器。

## P 问题和 NP 问题

- **P 问题**：就是能在多项式时间内解决的问题；即算法的时间复杂度是多项式级的。比如n个数中间找到最大值，或者n个数排序之类的。
- **NP 问题**：就是能在多项式时间验证答案正确与否的问题；即求问图中起点到终点是否有一条小于 100 个单位长度的路线。

## 梯度消失和梯度爆炸？

链式法则计算梯度时，下层梯度计算小于 1，经过层层累积，上层梯度越来越小，即上层权重更新速率低于下层权重更新速率，导致梯度消失，梯度爆炸则是上层权重更新速率高于下层权重更新速率。
产生原因：层数过多，激活函数不正确
解决：选择合适激活函数，BN/LN
[[梯度消失 & 梯度爆炸]]


## BN 和 LN 的区别？

都是用于解决 内部协变量偏移问题

BN：针对不同样本的同一特征（维度）数据，进行归一化，考虑所有样本的同一维度，因此比较适合大batch-size，而且数据分布比较接近的，不适用于动态的网络结构 和 RNN 网络。
LN：针对同一样本的不同特征数据进行归一化，因为LN考虑单个样本所有特征，因此适合用于NLP任务中，

## 实习的难点
- 【项目整体把握】做项目的整体过程，对一个项目，通常调研不是很充分，通常就是边做边规划，而在工作中通常需要有一个完整的调研，然后规划出几个月的任务安排，任务安排到天，这需要对对整个项目有一个清晰的认知。 
- 【调研】学校时通常只需要调研当前学术论文；这里调研时，得需要对当前国内外整个行业进展调研，他们完成了哪些内容，达成了哪些指标，我们要做的内容是什么，达成怎样的治标，为什么要这样做，不这样做行不行，多久能做出来。
- 【项目难点】项目开始时的难点是，对一个问题进行数学建模，转换成强化学习的模式。搭建整个系统框架。
- 【任务汇总】任务汇报的时候，不同于学校的一些技术、组会、答辩汇报，通常是面向技术的汇报；对领导汇报时，内容要充实，汇报要抓好重点，需要更加简洁、清晰、明了的解释你在做的东西或你将要去的东西，需要更好的总结，不仅面向技术，还要有整体任务的把握。

## 项目流程
- 【调研】；调研当前国内外研究现状，并对它们实现的效果及优缺点进行总结，复现已有的代码。
- 【任务方案】根据项目要求，写一个基础的项目实现方案，明确任务目标，选择合适算法，明确算法的输入输出，接下来去选择合适的仿真平台。
- 【环境搭建】完成仿真平台的搭建，测试是否可以得到我们想要的数据，测试是否可以实现交互，编写合适的算法，并测试模型是否可以正常运行，
- 【算法交互】完成算法与仿真环境的交互，在交互过程中，打印奖励函数、损失函数，根据反馈的信息不断调参。
- 【验证测试】设计不同的测试方案，对算法进行测试验证。

# 2. 经典图论算法
## 图的基本概念
**有向图**：每条边都是无方向的
**无向图**：每条边都是有方向的
**完全图**：任意两个点都有一条边相连
**二分图**:   顶点集V可分割为两个*互不相交的子集*，并且图中每条边依附的两个顶点都分属于这两个互不相交的子集，两个子集内的顶点不相邻。
**网**：边/弧带权的图
**关联**（依附）：边/弧与顶点之间的关系

**顶点的度**：与该顶点相关联的边的数目
> 在有向图中，顶点的度等于该顶点的入度和出度之和

**有向树**：当有向图中仅有一个顶点的入度为 0，其余顶点的入度均为 1
**路径**：接续的边构成的顶点序列
**路径长度**：路径上边或弧的数目/权值之和
**回路**（环）：第一个顶点和最后一个顶点相同的路径
**简单路径**：除路径起点和终点可以相同外，其余顶点均不相同的路径
**简单回路**（环）：除路径起点和终点相同外，其余顶点均不相同的路径
![[graph1.png]]

有向图中，1->3
**弧头**：箭头指向; 3
**弧尾**：箭头始发; 1

**连通图（强连通图）**：从无（有）向图 G=(V,{E})，若对于任何两个顶点 v、u 都存在从 v 到 u 的路径，则称 G 是连通图（强连通图）
**连通分量**（强连通分量）：无（有）向图 G 的**极大（强）连通子图**称为 G 的（强）连通分量
>极大连通子图：该子图是 G 连通子图，将 G 的任何不在该子图中的顶点加入，子图不在连通。

**极小连通子图**：该子图是 G 的连通子图，在该子图中删除任何一条边，子图不在连通。
**生成树**：包含无向图 G 的所有顶点的极小连通子图。
**生成森林**：对非连通子图，由各个连通分量的生成树的集合

## 构造最小生成树：Kruskal & Prim

**Prim**：不断选择与临时顶点集（初始仅一个顶点）相关联且权值最小的边放入生成树中，并将其对应的顶点加入临时顶点集。
**Kruskal**：已知所有顶点，直接选择选择权值最小的边加入生成树，同时避免成环。
**对比**：
- Prim 每一步得到的边导出子图都是连通的，而 Kruskal 不一定联通。
- 虽然都是选点，其算法思想，Prim 选点，Kruskal 选边。
- Prim算法适用于稠密图，Kruskal适用于稀疏图

[[6. 图#普里姆（Prime）算法]]

## 图的遍历：DFS & BFS
应用：图中可能存在回路，寻找图的生成树。

**DFS**：相当于树的先根遍历；
>是按照一个路径一直访问到底，当前节点没有未访问的邻居节点时，然后**回溯**到上一个节点，不断的尝试，直到访问到目标节点或所有节点都已访问

**BFS**：相当于树的层次遍历
> 按层次访问的，先访问源点，再访问它的所有相邻节点，并且标记结点已访问，根据每个邻居结点的访问顺序，依次访问它们的邻居结点，并且标记节点已访问，重复这个过程，一直访问到目标节点或无未访问的节点为止。

**对比**:
- BFS 遍历节点是先进先出，一般使用队列作为辅助数据结构，DFS 遍历节点是先进后出，一般使用栈作为辅助数据结构；
- BFS 适用于求源点与目标节点距离近的情况，例如：求最短路径。DFS 更适合于求解一个任意符合方案中的一个或者遍历所有情况，例如：全排列、拓扑排序、求到达某一点的任意一条路径。

## 图的匹配: 二分图匹配

**二分图**:   把一个图的顶点划分为两个不相交集 U和V ，使得每一条边都分别连接U、V中的顶点。。

**匹配：** 是一个边的集合，其中任意两条边都没有公共顶点

**最大匹配**：一个图所有匹配中，所含匹配边数最多的匹配，称为这个图的最大匹配。

**完美匹配**：如果一个图的某个匹配中，所有的顶点都是匹配点，那么它就是一个完美匹配。显然，完美匹配一定是最大匹配（完美匹配的任何一个点都已经匹配，添加一条新的匹配边一定会与已有的匹配边冲突）。但并非每个图都存在完美匹配。

**应用：**
【人员分配问题】：n 个工人去做 m 项工作，用二分图来表示工人与工作之间的关系
【男孩女孩匹配】：如果在某一对男孩和女孩之间存在相连的边，就意味着他们彼此喜欢，最多有多少互相喜欢的男孩/女孩可以配对儿。

**二分图最大匹配的生成算法：匈牙利算法**



## 图的应用: TSP & VRP


**TSP 问题**: 旅行商问题, 一个经典的组合优化问题。可以描述为：一个商品推销员要去若干个城市推销商品，该推销员从一个城市出发，需要经过所有城市后，回到出发地。应如何选择行进路线，以使总的行程最短

**VRP 问题**: 它是指一定数量的客户，各自有不同数量的货物需求，配送中心向客户提供货物，由一个车队负责分送货物，组织适当的行车路线，目标是使得客户的需求得到满足，并能在一定的约束下，达到诸如路程最短、成本最小、耗费时间最少等目的。

两种问题解决: TSP 和 VRP 问题实质是在一个带权完全无向图中，找一个权值最小的 Hamilton 回路。由于该问题的可行解是所有顶点的全排列，随着顶点数的增加，会产生组合爆炸，它是一个 NP 完全问题。
>哈密顿回路：若G中一个回路通过且仅通过每一个顶点一次

精确解解决；或利用启发式算法来解决

**PSO算法流程**

1.  初始化一群规模为M的粒子，包括随机位置和速度
2.  评价每个粒子的适应度、并得到Pbest、Gbest（位置）
3.  对每个粒子
    -   当前位置的适应度值与Pbest比较，如果较好，用当前位置替换Pbest
    -   比较当前位置适应度值与Gbest比较，如果较好，用当前位置替换Gbest
    -   调整粒子速度和位置
4.  若未达到结束条件则继续步骤3






Dijkstra 算法：

求单源最短路径的算法。即求网络中某个特定点v到网络中其他所有节点的最短路径。


# 3. 机器学习


## 回归

线性回归和逻辑回归都是**广义线性回归模型的特例**

**线性回归**
找到一个最优的模型来描述数据，有两个问题，如何定义最优、如何寻找最优；
定义最优的方法就是均方误差，各个点到直线的欧氏距离，寻找最优就是如何找到这个直线；一般有两种方法，最小二乘法和梯度下降法；最小二乘法就是找到所有极值点在比较，梯度下降法，沿着梯度方向进行寻优，通过学习率控制学习步幅。


**逻辑回归**

解决分类问题，逻辑回归使用的联系函数是 Sigmoid 函数，逻辑回归也是广义线性回归中的一种以对数几率函数为联系函数的特例。使用极大似然法进行参数估计，它是通过**最大化预测属于实际的概率**来最小化预测和实际之间的“距离。

> 联系函数：不同的方式映射，可以是对数，可以是指数，也可以是其他更复杂的函数。线性回归无联系函数或不起作用

## 分类
朴素贝叶斯：[[4. 朴素贝叶斯]]
**问题解决**：通过朴素贝叶斯算法完成对实例 x 的分类
**步骤**：
- 利用极大似然估计法/贝叶斯估计去计算先验概率 $P(Y=c_k)$ 和条件概率 $P(X^{(j)} = a_{jl} \mid Y= c_{k})$
- 利用贝叶斯定理与学到的联合概率模型（先验概率、条件概率）计算后验概率：
	- 对于给定的实例（特征向量）$x_{i}=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T$  —— 例如 ：$x=(2,S)^T$ 去计算：
$$
P\left(Y=c_{k}\right) \prod_{j=1}^{n} P\left(X_{j}=x^{(j)} | Y=c_{k}\right)
$$
- 通过朴素贝叶斯分类器，将实例分到后验概率最大的类中。


通过交叉熵来对比模型预测结果和数据的真实标签，随着预测越来越准确，交叉熵的值越来越小。
[[常用解释#熵 & 交叉熵]]

## 聚类
**K-menas 算法**

Kmeans算法具体步骤：
> -   根据特定的方法选择 K 个质心，作为初始的质心;
> -   计算每个样本点到质心的距离，并将其归到距离其最近的质心中; 
> -   当每个样本点都分配完成以后，重新计算 K 个质心的位置;
> -   重复步骤 2 和 3，直到所有的样本点不再被分配或是达到最大的迭代次数。


Kmeans 算法改进方法:
- K 值初始化；相对较远，离样本越近；K的数量改进
- 度量方式吧，欧氏距离不一定都适用。




# 4. 应用

**强化学习与调度：** 即时物流调度系统

目标：最小化

MDP 过程建模：

状态：任务数量、平均任务时间、待决策的任务数量、可用车辆的信息
动作：选择一个车辆
奖励：任务解决的数量、时间、每执行一步的负奖励





ADD

Hard算法
动态规划

