---
aka description: 《深度学习入门：基于Python的理论与实践》
---

# 《深度学习入门：基于Python的理论与实践》上

  

## 一、 感知机（Perceptron）

**基本结构**：感知机接收多个输入信号，输出一个信号。

**组成：**
* 权重$w$：控制输入信号的重要性的参数
* 偏置$b$：调整神经元被激活的容易成都的参数
* 神经元：输入信号送往神经元时，会被乘以固定的权重($w_1x_1$,$w_2x_2$)。神经会计算传送过来的信号总和，总和超过某个界限($\theta$;阈值)时，神经元被激活。

**单层感知机与多层感知机**：
* 单层感知机可以实现与门、非门、或门三种逻辑电路。感知机的局限性在于它只能表示由一条直线分割的空间（**线性空间**），而对于由于曲线分割而成的空间（**非线形空间**），例如异或门，无法用单层感知机表示，需要由多层感知机表示。
* 多层感知机：叠加多层的感知机称为多层感知机（异或门由两层感知机组成）。 $\rightarrow$ 引出接下来的神经网络
* 单层感知机只能表示线性空间，而多层感知机可以表示非线形空间。
* **感知机局限**:需要人工设定合适的、符合预期的输入与输出的权重。

  
## 二、 神经网络基础

### 2.1 基本结构：

最左边一列称为**输入层**，中间的一/几列称为**中间层（隐藏层）** ，最右边一列称为**输出层**。

### 2.2 激活函数：
**作用**：将输入信号的总和转换为输出信号的函数h(x)
**描述**：
$$
\begin{align*}
& a = b + w_1x_1 + w_2x_2 \\
& y=h(a)
\end{align*}
$$

> 感知机之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号。


**激活函数为什么不能采用线形函数？**
使用线性函数的话，加深神经网络的层数就没有意义了，因为使用线性函数时，无论如何加深层数，总可以找到一个与之等效的“无隐藏层的神经网络”。
> 例如激活函数为h(x) = cx ; 三层神经网络计算后可以得到y(x) =h(h(h(x))) = $c^3x$同样的处理，可以由y(x) = ax (a=$c^3$)代替

 **常用激活函数**：（感知机中神经元采用阶跃函数）
* Sigmoid函数：
  $$
h(x) = \frac{1}{1+exp(-x)}
$$
* ReLU 函数：
$$

h(x)= \begin{cases}x & \text { if } x>0 \\ 0 & \text { if } x \leq 0\end{cases}

$$

  

### **2.3 各层之间矩阵计算**
![第一层矩阵相乘](img/ANN1.png)

 >其中偏置的数量与下一层神经元个数相对应

  

### **2.4 输出层设计**

* **回归问题**：恒等函数
对于输入信息，不加以任何改动直接输出。

* **分类问题**：softmax函数

$$

y_{k}=\frac{\exp \left(a_{k}\right)}{\sum_{i=1}^{n} \exp \left(a_{i}\right)}

$$

> 特点：softmax的输出是0.0到1.0之间的实数，且输出值的总和是1；因此可以将其输出解释为概率。通常在推理阶段会省略输出层的softmax函数。
> 缺点：softmax函数在计算机的运算中存在一定的缺陷，即会发生**溢出问题**
> 改进： $C'$通常是输入信号中的最大值，可以通过减去这个最大值去防止溢出。 $$
 y_k=\frac{\exp \left(a_{k}+\mathrm{C}^{\prime}\right)}{\sum_{i=1}^{n} \exp \left(a_{i}+\mathrm{C}^{\prime}\right)}
$$


### 总结

* 神经网络问题的步骤可以分为**学习**和**推理**两个阶段；学习阶段使用训练数据（学习数据）进行权重、偏置参数的学习，推理阶段利用刚才学习到的参数，对测试数据进行测试。
* 神经网络的输入时通常需要进行预处理操作：
* 正规化（normalization）：把输入数据限定到某个范围内
* 白化（whitening）：把数据整体的分布形状均匀化

  

## 三、 神经网络的学习

神经网络的学习是指以损失函数为基准，找到能使它的值达到最小的权重参数，从而在训练数据中自动获取最优权重参数。

### 3.1 从数据中学习

神经网络的特征就是可以从数据中进行学习，可以利用数据自动决定权重参数的值；尽可能减少人为介入，从数据中发现答案。

  
#### 3.1.1 数据处理方法

* **传统机器学习**：例如在计算机视觉领域，可以先从图像中提出**特征量**（SIFT、SURF、HOG等），在用机器学习技术（SVM、KNN等）学习这些特征量。

> 将图像转为向量时使用的特征量仍是人为设计的，对于不同的问题，仍然需要设计合适的特征量，才可以得到较好的结果。

* **神经网络**(深度学习)：神经网络中对于上述的特征量可以直接由机器来学习，因此对于相似的问题可以用同样的流程来解决。对于**端到端（end-to-end）** 的学习方式，可以直接从原属数据（输入）中获得目标结果（输出）。

#### 3.1.2 训练数据和测试数据：

* 训练数据（监督数据）：使用训练数据，寻找最优的参数。
* 测试数据：使用测试数据评价训练得到的模型的实际能力，即测试模型的泛化能力。对某个数据集过度拟合的状态称为过拟合（over fitting）**。**

### 3.2 损失函数

损失函数是描述神经网络模型“优良程度”的**指标**，神经网络可以以该指标为线索寻找最优权重参数。


#### 3.2.1 均方误差（mean squared error）：

$$
E=\frac{1}{2} \sum_{k}\left(y_{k}-t_{k}\right)^{2}
$$
$y_k$为神经网络的输出，$t_k$为正确解标签，均方误差会计算神经网络的输出和正确解监督数据各个元素之差的平方，在求总和。

#### 3.2.2 交叉熵误差（cross entropy error）

$$

E=-\sum_{k} t_{k} \log y_{k}

$$

交叉熵误差的值是由正确解标签所对应的输出结果决定的，也就是说正确解标签对应的输出($y_k$)越小，则误差越多。

  

#### 3.2.3 mini-batch 学习

我们从训练数据中选出一批数据（mini-batch），作为全部数据的“近似“，然后对每个mini-batch进行学习，这种学习方式称为mini-batch学习。

#### 3.2.4 损失函数的设定

*为什么需要设定损失函数作为指标？

在反向传播求导时，如果选用识别精度作为指标时，参数的导数在绝大多数地方都会变成0，导致参数无法更新。稍微改变一下参数值，识别精度的变化是**不连续的、离散**的（32%、33%），而损失函变化是**连续性**的(0.9253、0.9342)。因此识别精度对微小的参数变化几乎没什么反应，即使有反应也是不连续的，突然地变化。

> 类似的，之所以不采用**阶跃函数**作为激活函数，就是因为微小的参数变化会被阶跃函数忽略，导致损失函数的值不会产生任何变化。

  

## 四、 数值微分和梯度

#### 4.1 数值微分

利用微小的差分求导数的过程称为**数值微分**，利用数值微分可以计算权重参数的梯度（严格来说，是损失函数关于权重参数的梯度）。数值微分实现起来很简单，但是比较费时间（存在大量参数）。  

> 而基于数学式的推导强求导数的过程，称为**解析性**求导（误差反向传播）。

#### 4. 2 梯度

* **梯度**（gradient）：由全部变量的**偏导数**汇总而成的向量称为梯度。梯度表示的是各点处的函数值减小（增加）最多的方向，因此无法保证梯度所指的方向就是函数的最小值或者真正前进的方向。
* **梯度法**（gradient）：通过不断的沿梯度方向前进，逐渐减少函数值的过程。虽然梯度的反向并不一定指向最小值，但沿着它的方向能够最大限度地减少函数的值。
* **梯度下降**（gradient descent method）：寻找最小值的梯度法。一般来说，神经网络中，梯度法主要只得是梯度下降
* **梯度上升**（gradient ascent method）：寻找最大值的梯度法。
* **神经网络梯度**：

$$
\begin{gathered} \mathbf{W}=\left(\begin{array}{lll} w_{11} & w_{12} & w_{13} \\ w_{21} & w_{22} & w_{23} \end{array}\right) \\ \frac{\partial L}{\partial \boldsymbol{W}}=\left(\begin{array}{ccc} \frac{\partial L}{\partial w_{11}} & \frac{\partial L}{\partial w_{12}} & \frac{\partial L}{\partial w_{13}} \\ \frac{\partial L}{\partial w_{21}} & \frac{\partial L}{\partial w_{22}} & \frac{\partial L}{\partial w_{23}} \end{array}\right) \end{gathered}
$$
神经网络的梯度，是指损失函数关于权重参数的梯度；$\frac{\partial L}{\partial \boldsymbol{W}}$的元素由各个元素关于 W 的偏导数构成。例如$\frac{\partial L}{\partial \boldsymbol{w_{11}}}$表示当$w_{11}$稍微变化时，损失函数 L 会发生多大变化。

  
#### 4. 3 学习率

学习率决定在一次学习中，应该学多少，以及在多大程度上更新参数。如果学习率过大，会发散成一个很大的值，反过来，如果学习率过小的话，基本上没怎么更新就结束了。

#### 4. 4 学习算法的实现

1. **mini-batch**：从训练数据中随机选出一部分数据（mini-batch），我们的目标是减少mini-batch的损失函数的值

2. **计算梯度**：为了减少mini-batch的损失函数的值，需要求出各个权重参数的梯度，梯度表示损失函数的值减少最多的方向。

3. **更新参数**：将权重参数沿梯度方向进行微小更新。然后不断重复迭代。

> **随机下降法（stochastic gradient descent；SGD）**：在这里使用的数据是随机选择的mini batch 数据，然后通过梯度下降法更新参数。

  

## 五、 误差反向传播法

### 5.1 计算图

在**计算图**（computational graph）中，从“左向右进行计算”是一种正方向的传播，称为**正向传播**（forward propagation），从“右向左进行计算”是一种反方向的传播，称为**反向传播**（backward propagation）。

* **局部计算**：计算图的特征是可以通过传递“局部计算”获得最终结果。其中局部计算是指，无论全局的计算多复杂，都能只根据与自己相关的信息输出接下来的结果。虽然局部计算非常简单，但是通过传递它的计算结果，就可以获得全局的复杂计算的结果。

* **计算图优点**：可以通过正向传播和反向传播高效地计算各个变量的导数值。

* 计算图可以集中精力于局部计算，从而简化问题。

* 利用计算图可以将中间的计算结果全部保存起来。

  

### 5.2 反向传播

反向传播将局部导数向正方向的反方向传递局部导数的原理，是基于**链式法则**（chain rule）的。其中链式法则是关于复合函数的导数性质。

#### 5.2.1 加法节点 & 乘法节点

* **加法节点**的反向传播只是将输入信号输出到下一个节点。
* **乘法的反向**传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传递给下游。

#### 5.2.2 举例

对于Sigmoid层反向传播计算：神经网络的反向传播会把这个差分表示的误差传递给前面的层，在每个子层计算时采用链式法则进行局部计算。

  
![](img/backward.png)

  

#### 5.2.3 损失函数设计对反向传播的影响

* **分类**问题中：使用交叉熵误差作为输出层softmax函数的损失函数后，反向传播会得到($y_1-t_1$,$y_2-t_2$,$y_3-t_3$) 这样可以直接看出与标签差值的结果。

* **回归**问题中：使用平方和误差作为输出层“恒等函数”的损失函数，反向传播仍然会得到上述相同的结果。

> 如果在方向传播过程中，存在一个较大的误差，那么前面的层学到的内容就会比较“大”，反之亦然。

  

#### 5.2.4 误差反向传播梯度确认

相较于数值微分，即使存在大量的参数没，误差反向传播法也可以高效的计算梯度。而误差反向传播的实现比较复杂，容易出错，因此在确定反向传播法是否正确时，是需要用数值微分的，通过数值分析法，可以确定数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（非常相近），这种操作称为**梯度确认**（gradient check）。

  

## 六、 与学习相关的技巧

  

### 6.1 参数的更新

神经网络学习目的是找到使损失函数的值尽可能小的参数，这种寻找最优参数的过程称为最优化（optimization）。

#### 6.1.1 SGD （随机梯度下降）

$$

\boldsymbol{W} \leftarrow \boldsymbol{W}-\eta \frac{\partial L}{\partial \boldsymbol{W}}

$$

其中$\eta$表示学习率，上面式子直接根据梯度下降更新权重参数。SGD虽然计算较为简单，但是存在一定的缺点，如果函数的形状非均向，比如延伸状（$f(x,y)= x^2 + y^2$），更新路径（“之字形路径”）就会非常低效，根本原因是，梯度的方向并没有指向最小值的方向。

> SGD可以类比为在复杂地形中，没有地图，不能睁眼的情况下，需要尽快完成“下山任务”，虽然看不到周围情况，但是能够感受当前所在位置不同地面的坡度，只要朝着当前所在位置的坡度最大方向前进，不断重复这一策略，就可以下山。

#### 6.1.2 Momentum（动量）

$$

\begin{gathered} \boldsymbol{v} \leftarrow \alpha \boldsymbol{v}-\eta \frac{\partial L}{\partial \boldsymbol{W}} \\ \boldsymbol{W} \leftarrow \boldsymbol{W}+\boldsymbol{v} \end{gathered}

$$
加入了一个新的变量$v$,对应于物理上的速度。第一个公式表示了物体在梯度方向上受力，在这个力的作用下，物体的速度不断增加。$\alpha v$这一项，在物体不受任何力时，该项承担使得物体逐渐减速的任务（$\alpha$通常设为0.9左右），对应于物理上的地面摩擦力或空气阻力。其更新路径与SGD相比，减弱了“之”字形的变动程度。

  

#### 6.1.3 AdaGrad
$$
\begin{aligned} &\boldsymbol{h} \leftarrow \boldsymbol{h}+\frac{\partial L}{\partial \boldsymbol{W}} \odot \frac{\partial L}{\partial \boldsymbol{W}} \\ &\boldsymbol{W} \leftarrow \boldsymbol{W}-\eta \frac{1}{\sqrt{\boldsymbol{h}}} \frac{\partial L}{\partial \boldsymbol{W}} \end{aligned}
$$

AdaGrad采用**学习率衰减**（learning rate decay）的方法，随着学习的进行，AdaGrad会为参数的每个元素适当的调整学习率，同时AdaGrad会记录**历史梯度信息**。具体实现为：通过变量 $h$  保存以前的所有梯度值的平方和。然后通过乘以$\frac{1}{\sqrt h}$就可以调整学习的尺度，例如参数的元素变化比较大（被大幅更新）的元素的学习率将变小。因此 AdaGrad开始时变动较大，但后面会根据这个较大的变动，按比例进行调整，减小更新的步伐，减少“之”字形的变动程度。

> 随时学习的深入，学习率会不断变小，如果学习率很低时，更新幅度就会变得很小，为了改善这个问题，可以采用RMSProp方法，它并不是将过去所有的梯度一视同仁的相加，而是逐渐遗忘过去的梯度，在进行加法运算时将新梯度的信息更多地反应出来，这种操作称为**指数移动平均**，即呈指数函数式的减小过去的梯度的尺度。

#### 6.1.4 Adam

Momentum 参照小球在碗中滚动的物理规则进行移动，AdaGrad为参数的每个元素适当地调整更新步伐，Adam将这两个方法相融合，通过组合这两个方法的优点，同时加入了**超参数的“偏置校正”**，实现参数空间的高效搜索。综上，Adam的更新过程像Momentum类似的移动，但左右摇晃的程度有所减轻，这得益于学习的更新程度被适当地调整了。

  

### 6.2 权重初始化

在神经网络的学习中，权重初始值非常重要，很多时候权重初始值的设定关系到神经网络的学习是否能够成功。

####  6.2.1 神经权重初始值设为0（任意相同值）

 **导致问题**：
在神经网络中不能采用0（实际上不光是0初始化，将权值初始化为任意相同值，都很有可能使模型失效）。因为在误差反向传播的过程中，**所有的权重值都会进行相同的更新**。

 **解释**：
 例如在一个三层结构神经网络中，在正向传播的过程中，若输入层的权重为0，第二层隐藏层的神经元被传入相同的值（0），经过第二层激活函数计算后，会输出相同的值，从而输出层计算会得到固定的值；因此在反向传播时，权重会进行相同的更新，从而权重被更新为相同的值，并且拥有对称的值（重复的值）不管进行多少轮的正向传播和反向传播，得到的权重参数都一样，从而使得神经网络拥有不同权值的意义丧失。因此，它们都在计算同一特征，网络变得跟只有一个隐含层节点一样，这使得神经网络失去了学习不同特征的能力，神经网络就失去了其特征学习的能力。

 **分类讨论**

 模型所有w初始化为0，b随机初始化：刚开始时每轮只能从后往前更新一层的参数，但由于b的不同，在经过足够多的轮数后所有参数还是能得到更新的。但是这种方式更新较慢，且存在梯度消失、梯度爆炸等问题，通常不会这么干。
 
模型所有w随机初始化，b初始化为0：每一层的参数的更新与其后一层的b并没有关系，因此b的初始值不会影响BP算法的效果，所有权值和b都能得到更新。

解决方法：因此为了防止“权重均一化”（**瓦解权重对称结构**），权重必须随机生成初始值。

> 补充：线性回归和逻辑回归可以采用0初始[https://blog.csdn.net/qq\_32623363/article/details/115035765](https://blog.csdn.net/qq\_32623363/article/details/115035765)

  
#### 6.2.2 梯度消失和梯度爆炸与权重初始化

反向传播过程中，由于链式法则的求导法则，反向传播计算梯度时，梯度的大小与激活函数的导数以及权重相关，如果两者相乘在(0,1)之间，层数越多，导数相乘累积也就越来越小，从而发生**梯度消失**（gradient vanishing）的情况，相反，如果两者相乘大于1，经过层层传递，梯度越来越大，从而发生**梯度爆炸**（gradient explored）的情况。

因此在考虑初始化权重时要注意，如果初始权重较小，可能会发生梯度消失的情况，反之，可能会发生梯度爆炸。

> 参考：[https://www.zhihu.com/question/290392414/answer/2262481447](https://www.zhihu.com/question/290392414/answer/2262481447)



#### 6.2.3 Xavier 初始化

为了使各层的激活值呈现出更具广度的分布，推导了合适的权重尺度，如果前一层的节点数为n，则初始值使用标准差为$\sqrt \frac{1}{n}$的高斯分布进行初始化，使用Xavier初始值之后，前一层的节点数越多，要设定为目标节点的初始值的权重尺度就越小。

Xavier 初始值是以激活函数是**线性函数**为前提而推导出来的，因为**sigmoid**函数和**tanh**函数左右对称（**S型曲线函数**），且中央附近可以视作线性函数，所以这两个激活函数可以采用Xavier初始化。

#### 6.2.4 He初始化

对于**ReLu**激活函数，一般推荐使用Kaiming He等人推荐的初始值，如果前一层的节点数为n，则初始值使用标准差为$\sqrt \frac{2}{n}$的高斯分布进行初始化，相较于Xavier，因为ReLU的负值区域的值为0，为了使它更具有广度，所以需要2倍的系数。

### 6.3 Batch Normalization

以mini-batch为单位进行学习，**向神经网络中插入对数据分布进行正规化的层**，调整各层激活值的分布使其拥有适当的广度，

#### 6.3.1 BN基本流程

BN 对 mini-batch的m个输入数据集合 B求均值 $u_B$和方差$\sigma_B$ ，然后对输入数据进行均值为0、方差为1（合适的分布）的正规化。通常将这个处理插到激活函数的前面（或者后面），可以减少数据分布的偏向。

$$

\begin{aligned} \mu_{B} & \leftarrow \frac{1}{m} \sum_{i=1}^{m} x_{i} \\ \sigma_{B}^{2} & \leftarrow \frac{1}{m} \sum_{i=1}^{m}\left(x_{i}-\mu_{B}\right)^{2} \\ \hat{x}_{i} & \leftarrow \frac{x_{i}-\mu_{B}}{\sqrt{\sigma_{B}^{2}+\varepsilon}} \end{aligned}

$$

接着BN层会对正规化后的数据进行缩放和平移的变换，这样可以变换回原始的分布，开始时$\gamma$=1, $\beta$=0,然后通过学习调整到合适的值。

$$

y_{i} \leftarrow \gamma \hat{x}_{i}+\beta

$$
#### 6.3.2 BN优点

* 可以使学习快速进行，加速训练，提高模型精度（用上BN层之后可以让损失函数更平滑，可以使用更大的学习率，从而跳出不好的局部极值）
* 不会过度依赖权重初始值
* 抑制过拟合，一定程度上增加了泛化能力（降低Dropout等的必要性）
* 因此当神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以采用BN

  

### 6.4 正则化

通过权重衰减、几种方法可以来达到抑制过拟合的产生。

#### 6.4.1 过拟合

过拟合指的是只能拟合训练数据，但不能很好的拟合不包含在训练数据中的其他数据的状态。其中过拟合产生的原因包括：

* 模型拥有大量参数、表现力强
* 训练参数少


#### 6.4.2 权值衰减

因为过拟合原本是因为权重参数取值过大才发生的，因此权值衰减在学习过程中对大的权重进行惩罚，来抑制过拟合。

具体而言，权值衰减就是**在损失函数上加上权重的平方范数**（L2范数；各个元素的平方和）,用符号表示的话, 如果将权重记为 $\boldsymbol{W}$ ，L2范数的权值衰减就是 $\frac{1}{2} \lambda \boldsymbol{W}^{2}$, 然后将这个 $\frac{1}{2} \lambda \boldsymbol{W}^{2}$ 加到损失函数上。这里：

* $\lambda$ 是控制正则化强度的超参数。 $\lambda$设置得越大, 对大的权重施加的惩罚就越重。
* $\frac{1}{2} \lambda \boldsymbol{W}^{2}$ 开头的 $\frac{1}{2}$是用于将 $\frac{1}{2} \lambda \boldsymbol{W}^{2}$的求导结果变成 $\lambda \boldsymbol{W}$的调整用常量。

对于所有权重, 权值衰减方法都会为损失函数加上 $\frac{1}{2} \lambda \boldsymbol{W}^{2}$。因此, 在求权 重梯度的计算中, 要为之前的误差反向传播法的结果加上正则化项的导数 $\lambda \boldsymbol{W}$ 。


#### 6.4.3 Dropout

权重衰减可以适用于较为简单的网络模型，如果网络模型变得复杂，只用权值衰减就难处理。**Dropout是一种在学习的过程中随机删除神经元的方法**。

具体而言，训练时，每传递一次数据，就会随机选择隐藏层的神经元将其删除，被删除的神经元不再进行信号传递；测试时，虽然会传递所有神经元信号，但是对于各个神经元的输出，要乘上训练时的删除比例后在输出。

**补充：集成学习**

集成学习就是让多个模型单独进行学习，推理时在取多个模型的输出的平均值。在神经网络中，就是分别学习多个神经网络，测试时，以所有神经网络的平均值作为输出。**Dropout将集成学习的效果（模拟地）通过一个网络实现了**，它在学习过程中随机删除神经元，从而达到每一次都让不同的模型进行学习，测试时，通过对神经元乘以删除比例，可以取得模型的平均值。

### 6.5 超参数的验证

通过使用验证数据（validation data），去评判超参数（hyper- parameters）取值的好坏。常见的超参数包括：神经元个数、batch大小、学习率、权值衰减等。

#### 6.5.1 超参数的最优化

在进行超参数最优化时，一开始先大致设定一个范围，从这个范围中随机选出一个超参数（采样），用这个采样到的值进行识别精度的评估（回合数不宜过大），重复该操作，观察模型的结果，缩小超参数的范围。这是偏实践性的方法，如果需要更精炼的方法，可以采用贝叶斯最优化（Bayesian optimization）。

#### 总结

 **抑制过拟合的方法:**

* Batch Normalization（在激活函数前加入对数据分布进行正规化的层）
* 权值衰减（损失函数加上权重的平方范数）
* Dropout（随机删除神经元）