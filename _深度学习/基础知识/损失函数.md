# 损失函数

损失函数主要分为两类回归损失和分类损失

## 一、 回归损失：

**均方误差（MSE）/ 平方损失 / L2损失：**

$$
M S E=\frac{\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}{n}
$$

 **平均绝对误差(MAE)/L1 损失**

$$
M A E=\frac{\sum_{i=1}^{n}\left| y_{i}-\hat{y}_{i}\right|}{n}
$$

> 上面两种损失函数，只考虑误差的平均大小，不考虑其方向。

 **Huber损失函数：**

需要一个超参数𝛿 ,来定义离群值

$$
L_{\delta}(y, f(x))=\left\{\begin{array}{cc} \frac{1}{2}(y-f(x))^{2} & |y-f(x)| \leq \delta \\ \delta|y-f(x)|-\frac{1}{2} \delta^{2} & \text { otherwise } \end{array}\right.
$$

  **平均偏差误差（mean bias error）**

$$
f(x) = x * e^{2 pi i \xi x}
$$

  **Log-Cosh Loss （是比L2 更光滑的损失函数）**

$$
L(y, f(x))=\sum_{i=1}^{n} \log \cosh (y-f(x))
$$

  **Quantile Loss 分位数损失**（可以设置不同的分位点，控制高估和低估在loss中占的比重。）

$$
L_{\text {quantile }}=\frac{1}{N} \sum_{i=1}^{N} \mathrm{U}_{y>f(x)}(1-\gamma)|y-f(x)|+\mathrm{U}_{y<f(x)} \gamma|y-f(x)|
$$

## 二、 分类损失：

   **0-1 Loss： 常用于二分类问题**

$$
L(y, s)= \begin{cases}0, & y s \geq 0 \\ 1, & y s<0\end{cases}
$$

  **Hinge Loss/多分类 SVM 损失：**

在一定的安全间隔内（通常是 1），正确类别的分数应高于所有错误类别的分数之和。常用的是支持向量机.

$$
SVMLoss=\sum_{j \neq y_{i}} \max \left(0, s_{j}-s_{y_{i}}+1\right)
$$

  **交叉熵损失(Cross Entropy Loss)/负对数似然：**

$$
\text { CrossEntropyLoss }=-\left(y_{i} \log \left(\hat{y}_{i}\right)+\left(1-y_{i}\right) \log \left(1-\hat{y}_{i}\right)\right)
$$

> 在二分类/ 多分类问题中，通常接一个sigmid保证输出在\[0,1]范围内。

  **指数损失（Exponential Loss）：**

$$
l(Y, f(x))=e^{-Y f(x)}
$$

  **焦点损失（Focal Loss）：**

$$
\mathrm{L}_{f l}=\left\{\begin{array}{cc} -\left(1-y^{\prime}\right)^{\gamma} \log y^{\prime} \\ -y^{\prime \gamma} \log \left(1-y^{\prime}\right), & y=1 \\ y=0 \end{array}\right.
$$

> 在二分类交叉熵损失基础上进行改进
