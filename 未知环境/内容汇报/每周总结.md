
# 一、总结

## 1. 当前进度
**目标**：
在未知环境下，每个机器人在其激光雷达检测范围内，不断选择接下来要前往目标点，以最小的代价完成对未知环境的探索。

**分层控制结构**：
- 高层为目标决策层，用于为机器人决策接下来要前往的目标点；
- 低层为导航建图层，用于引导机器人无碰撞的到达所选目标点并完成定位建图与地图融合任务。

![[4-整体结构.png]]




## 2. 问题汇总
- [ ] **单一训练地图**，导致智能体在环境结构不相似的场景中表现较差
- [ ] 神经网络输入维数固定，**可扩展差**，无法实现神经网络的动态输入，进而无法扩展到通信受限场景和变智能体数量场景
- [ ] 仅使用Odom进行定位，随着机器人不断移动，可能会发生位置偏差
- [ ] Gmapping 实时建图以及地图合并（multirobot_map_merge） 过程中存在**地图飘移**的情况
- [ ] 智能体的“**短视**”问题，当前可选目标点（边界点）由智能体激光雷达最大感知距离进行计算

> 不合理目标点处理



## 3. 解决方法
- [ ] 以**课程学习**的方法增加训练场景的数量，根据智能体的表现//特定的回合，进行场景的切换
- [ ] 在神经网络中增加 **Transformer** 结构，以实现动态输入
- [ ] 传感器融合 & 地图匹配
	- 将里程计数据与其他传感器数据传感器融合（激光雷达）减少机器人定位误差；
	- 将机器人所在的位置与事先构建好的地图进行匹配（gmapping、amcl），可以提高机器人的定位精度。
- [ ] 对 Gmapping 算法以及 multirobot_map_merge 软件包进行**调参**等
- [ ] 可选目标点的计算改为**已建地图的边界点**信息（需要精准的定位、建图）





## 4. 可参考方法
- [ ] Teacher-Student 框架
- [ ] 策略蒸馏（Policy Distillation）


----




# 二、代码整理

https://github.com/Peace1997/marl_voronoi_tb3_exploration 

![[未知环境/img/1.png|500]]





## 三、课程学习训练

在Gazebo环境中，无法很好切换训练地图，而仅在一个地图下训练，很容易发生过拟合的情况，鲁棒性较差。为此，在同一场景下，设计了多个地图，根据智能体的表现//达到特定的回合时，进行场景的切换。


![[3-BO_map.png|400]]





## 四、Transformer学习
Transformer是一种基于**注意力机制**的神经网络架构，用于处理序列数据，尤其是在自然语言处理领域中广泛应用。

Transformer 由 Encoder 和 Decoder 两个部分组成。
- **Encoder：** 将输入序列进行编码，生成一个对应的上下文向量
- **Decoder：** 根据上下文向量和之前生成的输出序列，生成目标序列的预测


### 优势
在 RNN 中，输入数据是有先后顺序的，之前前面的输入数据输入计算完成后才能计算后面的输入数据，因此 RNN 无法同时并行计算。
在Transformer中，对于输入数据是可以同时输入的，通过注意力机制，输入序列中的每个位置都会被赋予一个权重，这些权重指示了该位置在整个序列中的重要性，因此可以同时**并行处理**。


### 整体结构
**输入层**：输入一个序列数据，并将每个元素映射为一个词嵌入向量 
> Word Embedding 、 Positional Encoding

**编码器层**：由多个自注意力机制和前馈神经网络组成的，它能够对输入序列进行并行处理并提取其特征表示
>  self-attention、feed forward、Add&Norm

**解码器层**：由多个自注意力机制和前馈神经网络组成，但它还包括一个注意力机制，用于将编码器层的输出与当前解码器的输入进行对齐和融合，从而生成输出序列。

![[_机器学习/img/transformer.png|300]]



