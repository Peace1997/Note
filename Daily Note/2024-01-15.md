
# 多模态LLM做自动驾驶决策器
`来自商汤的最新自动驾驶大模型DriveMLM，直接在闭环测试最权威榜单CARLA上取得了SOTA成绩`
#自动驾驶大模型 #DriveMLM

简述：将图像、激光雷达、交通规则和乘客需求输入该模型，就能给出驾驶方案，并具备可解释性（为什么要这样开）

优势：驾驶逻辑可控，过程具备**可解释性**，且更擅长解决**特殊和复杂情况**。

## 研究现状

目前，自动驾驶系统主要有两种方案，**模块化**和**端到端**。
- 模块化方案顾名思义，把自动驾驶任务拆解为**感知**、**定位**和**规控**三个模块，各模块各自完成任务，最后输出车辆控制信号。
- 端到端则是一个**整体的模型**，包含了上述感知、定位等等所有模块的功能， 最后同样输出车辆控制信号。

***模块化 & 端到端对比***
模块化方案的算法依赖**专家知识**，所有规则都需要提前手写、定义。如果在实际驾驶场景中碰到没有提前写入的情况，很可能导致系统失效。比如救护车、消防车这种不会按照交通规则行驶的车辆，让自动驾驶系统自己去处理就很容易出错。

端到端方案则是依赖**数据驱动**，虽然靠大量、真实情况下的驾驶数据，可以不断驱动系统能力进行迭代，但这同样对输入的数据要求很高，需要大量的标注数据，这无异增加系统训练和迭代的成本。端到端方案的神经网络还是一个“黑盒”，决策规划都在系统内部完成，**缺乏可解释性**。万一有问题，很难像模块化方案那样发现到底是哪一部分出了问题。

而对于增强端到端方案的可解释性，近年来也有许多研究将大语言模型（LLM）引入自动驾驶系统中，但缺点是LLM输出主要是语言，无法进一步用于车辆控制。

## DriveMLM
商汤提出了**DriveMLM**模型，它和现有自动驾驶系统行为规划模块中的决策状态对齐，可实现闭环测试中操控车辆，超过之前的端到端和基于规则的自动驾驶系统方法。

![[driveMLM.png]]

***DriveMLM框架***
- **行为规划状态对齐**：将语言输出与对于车辆控制可执行的决策进行多起
- **MLM规划器**：将多模态传感器输入转化为驾驶解释和对齐的决策。包括多模型分词器和基于MLLM的解码器
	- **多模型分词器**：负责将摄像头、激光雷达、用户语言需求、交通规则等各种输入转化为统一的token embedding。
	- **基于MLLM的解码器**：基于生成的token，再生成图片描述、驾驶决策和决策解释等内容。
- **高效的数据收集策略**：以低成本生成丰富的驾驶解释和对齐的决策。数据收集全部收集自CARLA仿真器，也就是目前自动驾驶领域被使用最多的开源仿真工具和闭环测试基准。

*相比现有自动驾驶数据，DriveMLM的数据有两个不同之处：*
1. 决策部分能够**与实际行为决策模块对齐**，方便我们将MLLM规划器的输出转换为控制信号，直接控制闭环驾驶中的车辆；
2. 包含**与人类的交互数据**，可以提高系统理解人类指令并做出反应的能力。

*如何实现语言信号转换为控制信号：*
它将LLM的语言决策输出，和成熟模块化方案中规控部分的**决策状态对齐**，由此LLM输出的语言信号就可转化为车辆控制信号。

*DriveMLM的最大优势和价值主要包含三个方面：*
1. 一致的决策指令设置使得DriveMLM可以直接与现有的**模块化AD系统（如Apollo）进行对接**，无需任何重大更改就能够实现闭环驾驶，让车真的跑起来。
2. 可以**直接输入自然语言指令**传达乘客需求或高级系统消息，交给模型来处理。这样一来，自动驾驶系统便能适应越发多样、高阶的驾驶场景。
3. 基于大模型不光输出结果还能给出**逻辑推理过程**的特性，DriveMLM作出的每一个行为和选择都会跟有详细的说明来解释它为什么要这么做。



