# 自动驾驶

# 一、 概论

**定义**：自动驾驶一般指车辆利用车载传感器来感知车辆周围的环境，根据感知获得道路、车辆位置和障碍物信息，控制车辆的转向和速度，从而使车辆能够安全、可靠地在道路上行驶，具体包括感知、定位、决策、控制等多个关联子系统。

**技术依靠**：AI、视觉计算、雷达、监控装置和全球定位系统的协同合作。

> AI:行人检测、物体识别、多传感器融合、路径规划、行为决策。

*自动驾驶分级*：

- L0级（人工驾驶）：警告和瞬时辅助
- L1级（辅助驾驶）：只能完成一项驾驶操作
- L2级（部分自动驾驶）：自适应巡航功能和车道保持辅助系统
- L3级（条件自动驾驶）：车辆在特定环境中可以实现自动加减速和转向，不需要驾驶员操作，但要随时准备接管车辆。
- L4级（高度自动驾驶）：在一定限制的条件下（低速），实现驾驶全程不需要驾驶员。
- L5级（完全自动驾驶）：完全自适应驾驶，适应任何驾驶场景。

*整体流程*：

无人车通过各类传感器对真实环境进行环境感知和建模，形成环境模型和局部地图，GPS和惯性导航系统根据它们进行定位与建图，生成全局地图，交付给行为决策与路径规划模块，此模块生成局部路径，传递至运动控制模块进行跟踪控制，车辆的实际状态进而发生改变。

车辆通过相机、传感器、雷达等元件，获取对环境信息的感知，更好地模拟人类驾驶员的感知能力和，从而理解自身和周边的驾驶态势。由传感器感知融合信息，根据驾驶需求进行任务决策，在能避开可能存在的障碍物前提下，通过一些特定的约束条件，规划出两点间多条可选安全路径，决策算法综合当前道路信息、车辆状态、环境信息，计算出最佳路线，最后由控制模块采取行动，控制车辆的油门、刹车和转向等驾驶动作，调节车辆行驶速度、位置和方向等状态，以保证汽车的安全性、操纵性和稳定性。


## 整体架构

### 硬件层
- **硬件层**：车载计算单元、GPS/IMU、摄像头、激光雷达、毫米波雷达、超声波雷达、人机交互硬件等计算或感知设备

### 软件层
- **软件层**：
  - 实时操作系统（Real Time Operating System，RTOS）：针对自动驾驶定制化的高实时、高并发、低时延的Linux操作系统
  - 运行时框架（Runtime Framework）：基于操作系统层的各算法调度框架，主要负责各模块之间的消息通信、资源分配和运行调度等。主要的框架包括：ROS和百度自研的Cybertron框架。
  - 各应用算法模块：地图引擎、高精定位、感知、规划、控制、端到端解决方案、人机交互接口。

### 云端服务层
- **云服务层**：主要运行在分布式计算的云端，为无人车提供各种服务，包括高精地图、仿真服务、数据平台、安全、在线升级。











# 三、 自动驾驶软件系统

## 1. Apollo

百度 Apollo 的**平台架构**：
- 云服务平台
- 软件平台
- 硬件平台
- 车辆平台


**软件模块**：
- 感知
- 预测：预测感知障碍物的未来运动轨迹；预测订阅定位和感知障碍物消息，当接收到定位的信息后，预测模块更新内部状态。 当感知模块发布感知障碍物消息时，触发预测实际执行。
- 定位：RTK & MSF
- 路由
- 规划
- 控制
- CANBus
- 高精地图
- 人机接口：DreamView可以查看自动驾驶车辆状态的模块，同时也可用来预测其他模块和实时控制车辆。
- 监测

## 2. Autoware 

构建在 ROS 平台上的自动驾驶开源软件框架：
- 定位：基于3D高精度地图和正态分布变换（NDT），使用从CAN消息和GNSS/IMU传感器获得的里程信息，通过卡尔曼滤波（Kalman）算法对定位结果进行修正。
- 识别：目标检测（深度学习+传感器融合）
- 规划：概率机器人技术、基于行为决策系统、深度学习方法
- 控制：通过速度和角度（曲率）的组合来定义车辆的运动
- 交互界面：Runtime Manager 的用户界面（定位、对象检测和路径跟踪）


## 3. 对比

Autoware不同的是，Apollo3.5以后的版本，替换了原有的Ros中间件，使用了自己的CyberRT中间件。

相比Autoware，Apollo的框架更加丰富和复杂，Autoware的代码完全开源,Apollo的代码还处于非完全开源状态。

















Socially compliant mobile robot navigation via inverse reinforcement learning 。通过人工神经网络和反向强化学习来完成协作导航任务。

多传感器融合（卡尔曼滤波、贝叶斯统计理论）

运动学、动力学、机械臂

自动驾驶混合式体系结构

自动驾驶行为决策的作用

A*算法

凸优化






%%# 二、 感知&定位

自动驾驶感知层包括**环境感知和车辆运动感知**（定位）两种类型。环境感知和车辆运动感知一起为自动驾驶提供决策层需要的所有信息。

主要任务有：车道线识别、车辆行人识别、交通标志与交通灯识别。

## 1. 环境感知

环境感知通过常用传感器（激光雷达、摄像头、毫米波雷达、超声波传感器、红外线传感器）提供本车和周围其他车辆等**障碍物的位置、相对距离、相对速度**等信息，而且要保证在行驶过程中对环境信息进行获取并处理过程的**连续性和实时性**，从而为路径规划、实时决策和行车控制提供依据。

## 2. 车辆运动感知（定位）

通过、GNSS（全球卫星导航系统：GPS、北斗）、IMU（惯性测量单元）等传感器为自动驾驶车辆提供**速度、位置、姿态**等信息。

> IMU: 利用汽车的初始速度、加速度和初始位置计算汽车位置和速度的装置，其核心是三轴加速度计的传感器和陀螺仪。

# 三、 决策&规划

**描述**：融合多传感信息，然后根据驾驶需求进行任务决策，接着在避开可能的存在的障碍物的前提下，通过一些特定的约束条件，规划出两点间多条可选安全路径，并在这些路径中选取一条最优的路径作为车辆的行驶轨迹。

>  对采集的信息进一步进行规划和决策，规划与决策在整车控制单元中进行，决策系统的任务是根据全局行车目标、自车状态及环境信息等决定驾驶行为、路径规划、速度规划等问题。
>
> 决策步骤负责生成离散决定，规划步骤负责时空连续的局部轨迹。

**决策与规划关键环节**： 路径规划、运动轨迹规划、行为决策、异常处理。

>  路径规划层主要进行全局路径规划，运动轨迹规划层主要进行局部路径规划和速度规划。

**决策与规划体系结构**：

- 分层递阶式体系结构：串联体系结构
- 反应式体系结构：并联体系结构，针对各个局部目标射击对应的基本行为
- 混合式体系结构：上面两种体系结构结构：在全局规划层次上，生成面向目标定义的分层递阶式行为，在局部规划层次上生成面向目标搜索的反应式体系的行为分解。





# 四、控制执行

在环境感知的基础之上，根据路径规划模块决策规划出的目标轨迹， 通过对转向、驱动、制动等方面的控制，执行规划决策模块下发的期望速度和期望转向角度。%%