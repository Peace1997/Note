

# PICO 动捕设备


## 通信方式
VR $\rightarrow$ 机器人： PICO VR 设备通过 Web Socket 发送 `VRData`消息
机器人$\rightarrow$ VR： 机器人通过 Web Socket 发送`RobotData`响应
内部处理： ROS 节点将 Protobuf 数据转换为 ROS 消息格式

| 阶段       | 数据流向  | 通信协议                        | 数据格式            | 说明                               |
| -------- | ----- | --------------------------- | --------------- | -------------------------------- |
| VR → 机器人 | 外部输入  | TCP/**UDP**/gRPC/Web Socket | **Protobuf**    | VR 设备传输操作指令（如手势、位姿）              |
| 机器人内部    | 节点间通信 | ROS Topic/Service/Action    | **ROS Message** | 控制模块解析 Protobuf，转换为 ROS 消息并控制机器人 |
| 机器人 → VR | 外部回传  | TCP/UDP/gRPC/WebSocket      | **Protobuf**    | 机器人状态或传感数据序列化后发送给 VR 设备用于实时渲染或反馈 |

## PICO 数据流

### PICO 原始数据

PICO VR 设备提供的原始数据包括：
- 时间戳信息
- 全身骨骼追踪数据（25dim）：每个骨骼点包括位置（xyz）和四元数 (xyzw)数据
	- 躯干骨骼（7 dim）
	- 下肢骨骼（8 dim）
	- 上肢骨骼（10 dim）
- VR 控制器的按钮和摇杆状态

| PICO 原始数据       | 名称                                      | 作用      |
| --------------- | --------------------------------------- | ------- |
| IMU 位置（x、y、z）   | `/geometry_msgs/Point_position`         | 机身位置    |
| IMU 姿态（x，y，z，w） | `/geometry_msgs/Quaternion orientation` | 机身姿态四元数 |

**骨骼点的数据结构：**
```protobuf
message Pose{
	double pos_x = 1;
	double pos_y = 2;
	double pos_z = 3;
	double rot_qx = 4;
	double rot_qy = 5;
	double rot_qz = 6;
	double rot_qw = 7;
}
```


**BODY_TRACKER_ROLES：**
```python
BODY_TRACKER_ROLES = [
	"Pelvis", "LEFT_HIP", "RIGHT_HIP", "SPINE1", "LEFT_KNEE", 
	"RIGHT_KNEE", "SPINE2", "LEFT_ANKLE", "RIGHT_ANKLE", "SPINE3",
	"LEFT_FOOT", "RIGHT_FOOT", "NECK", "LEFT_COLLAR", "RIGHT_COLLAR",
	"HEAD", "LEFT_SHOULDER", "RIGHT_SHOULDER", "LEFT_ELBOW", 
	"RIGHT_ELBOW", "LEFT_WRIST", "RIGHT_WRIST", "LEFT_HAND", "RIGHT_HAND"]
```


![[Pasted image 20251013144737.png|500]]

![[Pasted image 20251013165541.png|500]]


### 数据处理

1.  protobuf 解析 25 个骨骼点数据：
	- 解析每个骨骼点的位置和四元数姿态

2. 坐标系转换：从 Unity 坐标系 --》 ROS 坐标系 ---》机器人 URDF 坐标系
	- Unity 坐标系转 ROS 坐标系：将 Unity 世界坐标系转换为 ROS 世界坐标系。
	-  ROS 世界坐标系转 URDF 坐标系：将 ROS 世界坐标系转为本体坐标系。

3. 双臂手臂位姿获取
	- 从骨骼矩阵中提取手臂相关关节对应的位姿信息
	- 进行尺度缩放

4. 脚部轨迹获取：VR 数据 --》机器人内部计算 ---》ROS 消息
	 - 从骨骼矩阵中提取脚部位姿信息以及足底接触信息
	 - 基于 VR 检测到的动作生成轨迹
		- 生成足部索引轨迹（接触状态，0: 左脚摆动；1: 右脚摆动；2 双脚支撑）
		- 生成足部位姿轨迹（来自 VR 足部跟踪）
		- 生成躯干位姿轨迹（机器人内部计算）

5. VR 末端执行器获取
	- 从手柄数据中提取握持值
	- 根据末端执行器类型（灵巧手/夹爪）类型发布不同的消息

6. 自适应阈值校准
	- 自动校准抬脚高度阈值

### 话题发布

1. `/leju_pico_bone_pose` ： 骨骼数据
	- 25 个骨骼点的位置（xyz）和四元数姿态信息（xyzw）

2. `/mm/two_arm_hand_pose_cmd` & `/ik/two_arm_hand_pose_cmd` ：双臂手部末端位姿控制
	 - 控制模式为 MPC 模式，则发布到`/mm/two_arm_hand_pose_cmd` ，世界坐标系
	 - 控制模式为跟随模式，则发布到 `/ik/two_arm_hand_pose_cmd`，VR 坐标系

3. `/cmd_vel` ：基体速度控制
	- 从手柄数据中提取摇杆的值
	- 左摇杆控制前后和左右移动
	- 右摇杆控制旋转

4. `/cmd_pose`：身体姿态控制
	- 从骨骼矩阵中提取胸部姿态数据`SPINE3`
	- 计算身体姿态角度
	- 提取偏航、俯仰、滚转角的信息（俯仰角度限制 3-40 度）
	- 提取位置信息（高度限制 -0.4-0.1m）

5. `/humanoid_mpc_foot_pose_world_target_trajectories` ：脚步轨迹末端控制
	 - 从骨骼矩阵中提取脚部姿
	 - 并行检测脚部动作
	 - 生成脚部轨迹消息
	 - 添加到执行队列

6. `/control_robot_hand_position`：末端执行器控制
	- 从手柄数据中提取握持值
	- 根据末端执行器类型（灵巧手/夹爪）类型发布不同的消息

## 控制器数据流

### 控制器话题订阅

 **1. 移动手臂操作控制器**
- 数据来源：`/mm/two_arm_hand_pose_cmd` 
- 数据处理：
	- 根据手部位姿进进行关节角度 IK 求解
	- 执行 IK 求解并发布关节指令
- 数据结构（`armHandPose.msg`）：
	- 世界坐标系下的手臂的位姿 \[x, y, z] + \[x, y, z, w]
	- 世界坐标系下的手肘的位置 \[x, y, z]
	- 关节角度（通常为空）
- 场景适用：机器人在世界坐标下进行移动的场景


 **2. 手臂 IK 控制器**
- 数据来源：`/ik/two_arm_hand_pose_cmd` 
- 数据处理：
	- 根据手部位姿进行双臂 IK 求解
	- 发布关节轨迹到 `/kuavo_arm_traj`
- 数据结构
	- VR坐标系下的手臂的位姿 \[x, y, z] + \[x, y, z, w]
	- VR坐标系下的手肘的位置 \[x, y, z]
	- 关节角度（通常为空）
- 场景适用：基体不移动仅通过 VR 对手部进行控制

**twoArmHandPoseCmd.msg**
```
twoArmHandPose  hand_poses
# params for the IK solver
bool use_custom_ik_param
bool joint_angles_as_q0
ikSolveParam ik_param
int32 frame # 0. keep current frame  1. world frame (based on odom)  2.  local frame  3.  VRFrame  4.  manipulation world frame
```
**twoArmHandPose.msg**
```msg
Header header
armHandPose  left_pose
armHandPose  right_pose
```
**armHandPose.msg**
```msg
float64[3] pos_xyz
float64[4] quat_xyzw
float64[3] elbow_pos_xyz
float64[7] joint_angles  
```


**3. 全身运动控制-主动控制** 
- 数据来源：`/cmd_vel`，VR 手柄摇杆，主动操作控制
- 数据处理：VR 摇杆的机身速度指令处理
- 数据结构：`geometry/Twist`，本体坐标系下的速度
	- 线速度：\[x, y, z]
	- 角速度：\[x, y, z]


**4. 全身运动控制-被动跟随** 
- 数据来源：`/cmd_pose`，VR 头显和身体跟踪，被动姿态跟随
- 数据处理：VR 头部和胸部数据追踪
- 数据结构：`geometry/Twist`，相对机器人当前位姿的偏移量（世界坐标系）
	- 位置偏移量：\[x, y, z]
	- 姿态偏移量：\[x, y, z]

**Geometry_msgs/Twist.msg**
```
geometry_msgs/Vector3 linear
geometry_msgs/Vector3 angular

# geometry_msgs/Vector3.msg
float64 x
float64 y
float64 z
```


**5. 足部轨迹控制器**
- 数据来源：`/humanoid_mpc_foot_pose_world_target_trajectories`
- 数据处理：足部轨迹 MPC 规划和处理
- 数据结构 (`footPoseTargetTrajectories.msg`)：
	- 时间戳
	- 足部支撑状态（0: 右脚支撑；1: 左脚支撑；2: 双脚支撑）
	- 足部位姿（足部在世界坐标系中的位置和朝向；\[x, y, z, yaw]）
	- 躯干姿态（躯干在世界坐标系中的位置和朝向；\[x, y, z, yaw] , pelvis）

**footPoseTargetTrajectories.msg**
```msg 
float64[]    timeTrajectory
int32[]      footIndexTrajectory # 足部接触状态
footPose[]   footPoseTrajectory
footPoses[]  additionalFootPoseTrajectory  # 可选字段，用于存储额外的轨迹点规划值
float64[]    swingHeightTrajectory # 可选字段，用于存储swing高度轨迹
```
**footPose.msg**
```msg
float64[4] footPose # x, y, z, yaw
float64[4] torsoPose # x, y, z, yaw
```



**5. 末端控制器**
- 数据来源：`/control_robot_hand_position`
- 数据处理：手指关节处理

### 控制器消息转换

1. 双臂关节位置 IK 求解
- 订阅`ik/two_arm_hand_pose_cmd`话题
- 使用二分查找优化的 IK 求解器，直接将 VR 手部位姿转换为关节角度
- 通过`kuavo_arm_traj`将关节位置信息进行发布

2. MPC下肢控制执行
- 将 VR 的 4 Dim 轨迹数据转换为机器人控制所需的 6 Dim 消息
- 转换足部姿态：4 D  \[x, y, z, yaw] $\rightarrow$ 6 D \[x, y, z, yaw, pitch, roll]
- 转换躯干姿态：4 D $\rightarrow$ 6 D
 
# VMP 数据流

## 基本信息

控制频率：
原始数据提供：



## 参考数据来源

**基体高度**
- 话题消息数据来源：根据`/humanoid_mpc_foot_pose_world_target_trajectories`中 `footPose` 躯干位姿的高度信息。

 **关节位置信息：**
 数据来源： 末端位置解 IK
- 手臂关节位置获取：``
	- 根据`ik/two_arm_hand_pose_cmd`话题通过 IK 逆解求的关节位置，并将其发布为`/kuavo_arm_traj`。
- 腿部关节获取：根据`/humanoid_mpc_foot_pose_world_target_trajectories`中 `footPose` 话题在`calculateJointRef` 函数中求解，但求解的结果主要于内部的 MPC 轨迹规划。


**关节速度信息** 
数据来源：关节位置差分
- 手臂关节速度：根据`/kuavo_arm_traj` 消息进行差分获取
- 腿部关节速度：暂无


**基体姿态**
数据来源：`/humanoid_mpc_foot_pose_world_target_trajectories`中躯干姿态


**基体速度**
数据来源：
- 基体线速度：根据`/cmd_pose`的位置偏移量结合控频率计算线速度
- 基体角速度：根据`/cmd_pose`的姿态偏移量结合控频率计算角速度
gripper

**末端位置**
- 话题数据来源：
	- 足部位置：根据`/humanoid_mpc_foot_pose_world_target_trajectories` 中`footPose` 中的世界坐标系下足部的末端位置
	- 手臂位置：根据 `/mm/two_arm_hand_pose_cmd` 中世界坐标系下的手臂的末端位置。

**足底接触状态**：
- 数据来源：根据`/humanoid_mpc_foot_pose_world_target_trajectories` 中足部的支撑状态



大概看了一下实现源码，目前 PICO 提供的话题数据中：
`/leju_pico_bone_pose`: 24 个点的骨骼数据，可根据需要切换相应的
`/ik/two_arm_hand_pose_cmd`：VR 坐标系下双臂末端位姿
`/mm/two_arm_hand_pose_cmd`：世界坐标系下双臂末端位姿
`/humanoid_mpc_foot_pose_world_target_trajectories`： 世界坐标系下双足末端位姿

机身角速度、线速度和关节速度是不是都需要通过差分获得的，以及机身高度的信息和腿部的关节角度信息




## 重定向数据描述

0-1：高度信息
1-7：机身姿态 $2 \times 3$ 矩阵
7-13：机身速度（先线速度后角速度）
13-39：关节位置
39-65：关节速度
65-77：末端位置（4 x 3，世界坐标系）



# 算法实现

## 整体架构

VMP 算法部署在包含之前的离线轨迹播放功能的基础上，增加在线轨迹的播放功能
- 离线轨迹播放：支持特定轨迹的播放（单轨迹、多轨迹）
- 在线轨迹播放：
	- 支持提前录制的动捕数据的离线播放
	- 支持在线轨迹的播放


实现思路：
- 完成固定长度的环形缓存区的读写任务，可以通过在线导入离线的轨迹进行验证
- 完成话题的读取与预处理的测试，创建一个模拟话题发布的程序，给双臂发布正弦整理，VMP 控制器接收话题进行运动控制


## 缓存区

数据结构：固定长度的环形缓存区数据结构（FIFO 策略）
数据支持：
- Bin 格式的离线数据（可以先录一段时间的动捕设备数据进行播放，以验证算法的有效性
- VR 设备的在线数据
数据读写：
- **写入指针**：
	- 期望写入频率目前为 100 hz（受网络波动，频率会有变化）。
	- 写入指针从固定长度的一半开始写入，每次写入新帧后，写入指针前进 1 位
- **读取指针**：
	- 读取频率固定为 100 hz。
	- 读取指针从 0 帧开始读取，
		- 此时，假设固定长度为 200，历史帧 15 帧为环形缓存区的末尾数据（185-199），未来帧为环形缓存区 0 帧向后 14 帧的数据（1-14）
数据缓存 ：假设固定长度为 200，如果写入指针按照 100hz 的频率写入，则读取帧喝写入帧之前始终存在 100 帧的偏差，也就是为期 1s 的缓存。

## PICO 数据处理
VR 设备数据话题订阅 --- 数据预处理 --- 固定频率采样器


先拿一个话题进行模拟



### VR 读取获取
话题获取：
`/ik/two_arm_hand_pose_cmd`：VR 坐标系下双臂末端位姿
`/mm/two_arm_hand_pose_cmd`：世界坐标系下双臂末端位姿
`/humanoid_mpc_foot_pose_world_target_trajectories`： 世界坐标系下双足末端位姿



### 数据预处理



### 固定频率采样器

当前强化学习的更新频率是 100hz ，数据的更新频率是 50hz，为了维持 100hz 的数据输出，则需要对数据进行插值处理：
- 高度（线性插值）
- 机身姿态（6D ---> 四元数 --> **SLERP 插值** --> 6D）
- 机身速度（线性插值）
- 关节位置（线性插值）
- 关节速度（差分）
- 末端位置（根据世界坐标系下的位置差值后再根据关节位置做一个 FK）








