
动捕设备 ：
- 视觉输入：单目、双目以及深目相机
- 光学动作捕捉：Vicon、OptiTrack
- 惯性动作捕捉：诺亦腾无线 PNS 动捕、PICO


# PICO 动捕设备

## 通信方式
VR $\rightarrow$ 机器人： PICO VR 设备通过 Web Socket 发送 `VRData`消息
机器人$\rightarrow$ VR： 机器人通过 Web Socket 发送`RobotData`响应
内部处理： ROS 节点将 Protobuf 数据转换为 ROS 消息格式

| 阶段       | 数据流向  | 通信协议                        | 数据格式            | 说明                               |
| -------- | ----- | --------------------------- | --------------- | -------------------------------- |
| VR → 机器人 | 外部输入  | TCP/**UDP**/gRPC/Web Socket | **Protobuf**    | VR 设备传输操作指令（如手势、位姿）              |
| 机器人内部    | 节点间通信 | ROS Topic/Service/Action    | **ROS Message** | 控制模块解析 Protobuf，转换为 ROS 消息并控制机器人 |
| 机器人 → VR | 外部回传  | TCP/UDP/gRPC/WebSocket      | **Protobuf**    | 机器人状态或传感数据序列化后发送给 VR 设备用于实时渲染或反馈 |

## PICO 数据流

### PICO 原始数据

PICO VR 设备提供的原始数据包括：
- 时间戳信息
- 全身骨骼追踪数据（25dim）：每个骨骼点包括位置（xyz）和四元数 (xyzw)数据
	- 躯干骨骼（7 dim）
	- 下肢骨骼（8 dim）
	- 上肢骨骼（10 dim）
- VR 控制器的按钮和摇杆状态

| PICO 原始数据       | 名称                                      | 作用      |
| --------------- | --------------------------------------- | ------- |
| IMU 位置（x、y、z）   | `/geometry_msgs/Point_position`         | 机身位置    |
| IMU 姿态（x，y，z，w） | `/geometry_msgs/Quaternion orientation` | 机身姿态四元数 |

**骨骼点的数据结构：**
```protobuf
message Pose{
	double pos_x = 1;
	double pos_y = 2;
	double pos_z = 3;
	double rot_qx = 4;
	double rot_qy = 5;
	double rot_qz = 6;
	double rot_qw = 7;
}
```


**BODY_TRACKER_ROLES：**
```python
BODY_TRACKER_ROLES = [
	"Pelvis", "LEFT_HIP", "RIGHT_HIP", "SPINE1", "LEFT_KNEE", 
	"RIGHT_KNEE", "SPINE2", "LEFT_ANKLE", "RIGHT_ANKLE", "SPINE3",
	"LEFT_FOOT", "RIGHT_FOOT", "NECK", "LEFT_COLLAR", "RIGHT_COLLAR",
	"HEAD", "LEFT_SHOULDER", "RIGHT_SHOULDER", "LEFT_ELBOW", 
	"RIGHT_ELBOW", "LEFT_WRIST", "RIGHT_WRIST", "LEFT_HAND", "RIGHT_HAND"]
```


![[Pasted image 20251013144737.png|500]]

![[Pasted image 20251013165541.png|500]]


### 数据处理

1.  protobuf 解析 25 个骨骼点数据：
	- 解析每个骨骼点的位置和四元数姿态

2. 坐标系转换：从 Unity 坐标系 --》 ROS 坐标系 ---》机器人 URDF 坐标系
	- Unity 坐标系转 ROS 坐标系：将 Unity 世界坐标系转换为 ROS 世界坐标系。
	-  ROS 世界坐标系转 URDF 坐标系：将 ROS 世界坐标系转为本体坐标系。

3. 双臂手臂位姿获取
	- 从骨骼矩阵中提取手臂相关关节对应的位姿信息
	- 进行尺度缩放

4. 脚部轨迹获取：VR 数据 --》机器人内部计算 ---》ROS 消息
	 - 从骨骼矩阵中提取脚部位姿信息以及足底接触信息
	 - 基于 VR 检测到的动作生成轨迹
		- 生成足部索引轨迹（接触状态，0: 左脚摆动；1: 右脚摆动；2 双脚支撑）
		- 生成足部位姿轨迹（来自 VR 足部跟踪）
		- 生成躯干位姿轨迹（机器人内部计算）

5. VR 末端执行器获取
	- 从手柄数据中提取握持值
	- 根据末端执行器类型（灵巧手/夹爪）类型发布不同的消息

6. 自适应阈值校准
	- 自动校准抬脚高度阈值

### 话题发布

1. `/leju_pico_bone_pose` ： 骨骼数据
	- 25 个骨骼点的位置（xyz）和四元数姿态信息（xyzw）

2. `/mm/two_arm_hand_pose_cmd` & `/ik/two_arm_hand_pose_cmd` ：双臂手部末端位姿控制
	 - 控制模式为 MPC 模式，则发布到`/mm/two_arm_hand_pose_cmd` ，世界坐标系
	 - 控制模式为跟随模式，则发布到 `/ik/two_arm_hand_pose_cmd`，VR 坐标系

3. `/cmd_vel` ：基体速度控制
	- 从手柄数据中提取摇杆的值
	- 左摇杆控制前后和左右移动
	- 右摇杆控制旋转

4. `/cmd_pose`：身体姿态控制
	- 从骨骼矩阵中提取胸部姿态数据`SPINE3`
	- 计算身体姿态角度
	- 提取偏航、俯仰、滚转角的信息（俯仰角度限制 3-40 度）
	- 提取位置信息（高度限制 -0.4-0.1m）

5. `/humanoid_mpc_foot_pose_world_target_trajectories` ：脚步轨迹末端控制
	 - 从骨骼矩阵中提取脚部姿
	 - 并行检测脚部动作
	 - 生成脚部轨迹消息
	 - 添加到执行队列

6. `/control_robot_hand_position`：末端执行器控制
	- 从手柄数据中提取握持值
	- 根据末端执行器类型（灵巧手/夹爪）类型发布不同的消息

## 控制器数据流（queset3 ）

***（1）控制器话题订阅***

 **1. 移动手臂操作控制器**
- 数据来源：`/mm/two_arm_hand_pose_cmd` 
- 数据处理：
	- 根据手部位姿进进行关节角度 IK 求解
	- 执行 IK 求解并发布关节指令
- 数据结构（`armHandPose.msg`）：
	- 世界坐标系下的手臂的位姿 \[x, y, z] + \[x, y, z, w]
	- 世界坐标系下的手肘的位置 \[x, y, z]
	- 关节角度（通常为空）
- 场景适用：机器人在世界坐标下进行移动的场景


 **2. 手臂 IK 控制器**
- 数据来源：`/ik/two_arm_hand_pose_cmd` 
- 数据处理：
	- 根据手部位姿进行双臂 IK 求解
	- 发布关节轨迹到 `/kuavo_arm_traj`
- 数据结构
	- VR坐标系下的手臂的位姿 \[x, y, z] + \[x, y, z, w]
	- VR坐标系下的手肘的位置 \[x, y, z]
	- 关节角度（通常为空）
- 场景适用：基体不移动仅通过 VR 对手部进行控制

**twoArmHandPoseCmd.msg**
```
twoArmHandPose  hand_poses
# params for the IK solver
bool use_custom_ik_param
bool joint_angles_as_q0
ikSolveParam ik_param
int32 frame # 0. keep current frame  1. world frame (based on odom)  2.  local frame  3.  VRFrame  4.  manipulation world frame
```
**twoArmHandPose.msg**
```msg
Header header
armHandPose  left_pose
armHandPose  right_pose
```
**armHandPose.msg**
```msg
float64[3] pos_xyz
float64[4] quat_xyzw
float64[3] elbow_pos_xyz
float64[7] joint_angles  
```


**3. 全身运动控制-主动控制** 
- 数据来源：`/cmd_vel`，VR 手柄摇杆，主动操作控制
- 数据处理：VR 摇杆的机身速度指令处理
- 数据结构：`geometry/Twist`，本体坐标系下的速度
	- 线速度：\[x, y, z]
	- 角速度：\[x, y, z]


**4. 全身运动控制-被动跟随** 
- 数据来源：`/cmd_pose`，VR 头显和身体跟踪，被动姿态跟随
- 数据处理：VR 头部和胸部数据追踪
- 数据结构：`geometry/Twist`，相对机器人当前位姿的偏移量（世界坐标系）
	- 位置偏移量：\[x, y, z]
	- 姿态偏移量：\[x, y, z]

**Geometry_msgs/Twist.msg**
```
geometry_msgs/Vector3 linear
geometry_msgs/Vector3 angular

# geometry_msgs/Vector3.msg
float64 x
float64 y
float64 z
```


**5. 足部轨迹控制器**
- 数据来源：`/humanoid_mpc_foot_pose_world_target_trajectories`
- 数据处理：足部轨迹 MPC 规划和处理
- 数据结构 (`footPoseTargetTrajectories.msg`)：
	- 时间戳
	- 足部支撑状态（0: 右脚支撑；1: 左脚支撑；2: 双脚支撑）
	- 足部位姿（足部在世界坐标系中的位置和朝向；\[x, y, z, yaw]）
	- 躯干姿态（躯干在世界坐标系中的位置和朝向；\[x, y, z, yaw] , pelvis）

**footPoseTargetTrajectories.msg**
```msg 
float64[]    timeTrajectory
int32[]      footIndexTrajectory # 足部接触状态
footPose[]   footPoseTrajectory
footPoses[]  additionalFootPoseTrajectory  # 可选字段，用于存储额外的轨迹点规划值
float64[]    swingHeightTrajectory # 可选字段，用于存储swing高度轨迹
```
**footPose.msg**
```msg
float64[4] footPose # x, y, z, yaw
float64[4] torsoPose # x, y, z, yaw
```



**5. 末端控制器**
- 数据来源：`/control_robot_hand_position`
- 数据处理：手指关节处理

***（2）控制器消息转换***

1. 双臂关节位置 IK 求解
- 订阅`ik/two_arm_hand_pose_cmd`话题
- 使用二分查找优化的 IK 求解器，直接将 VR 手部位姿转换为关节角度
- 通过`kuavo_arm_traj`将关节位置信息进行发布

2. MPC下肢控制执行
- 将 VR 的 4 Dim 轨迹数据转换为机器人控制所需的 6 Dim 消息
- 转换足部姿态：4 D  \[x, y, z, yaw] $\rightarrow$ 6 D \[x, y, z, yaw, pitch, roll]
- 转换躯干姿态：4 D $\rightarrow$ 6 D




# 虚拟动点动捕设备

## 数据流


# VMP 数据流



## 基本信息

**策略输入：**
```
Policy Input = Observation + RefMotion + VAELatent + [EstimatorOutput]

v46 (无Estimator): 83 + 77 + 64 = 224
v46 (有Estimator): 83 + 77 + 64 + 64 = 288

v52 (无Estimator): 86 + 79 + 64 = 229
v52 (有Estimator): 86 + 79 + 64 + 64 = 293


```

**Observation：**

| 数据                | v 46 索引 | v 52 索引 |
| ----------------- | ------- | ------- |
| 关节位置偏移            | 0-25    | 0-26    |
| 关节速度              | 26-51   | 27-53   |
| 上一时刻动作            | 52-77   | 54-80   |
| 机身角速度             | 78-80   | 81-83   |
| 欧拉角 (roll, pitch) | 81-82   | 84-85   |
| **总维度**           | **83**  | **86**  |

**RefMotion：**

| 字段             | v 46   | v 52   |
| -------------- | ------ | ------ |
| h (高度)         | 0-1    | 0-1    |
| theta (姿态 6 D) | 1-7    | 1-7    |
| v (速度)         | 7-13   | 7-13   |
| q (关节位置)       | 13-39  | 13-40  |
| q_dot (关节速度)   | 39-65  | 40-67  |
| p (末端位置)       | 65-77  | 67-79  |
| **总维度**        | **77** | **79** |
> Kuavo_v46: 先手后脚，先左后右
> Kuavo_v 52：先脚后后，先左后右


**VAE**：
```
VAE Input Shape: [batch, window_l, in_c]
v46: [1, 30, 77]
v52: [1, 32, 79]  (注: window_l 可能不同)
```

**Estimator**
```
Estimator Input Shape: [batch, history_frames ， input_dim]
v46: [1, 8 ，83]
v52: [1, 8 ，86]
```

## 参考数据来源

**（1） PICO 数据流**
PICO重定后数据流通过一个话题进行发布（`/pico/retargeted_pose`）

```c
# Header with timestamp
std_msgs/Header header

# Base (root) pose in world frame
# Note: geometry_msgs/Pose.orientation is quaternion in (x, y, z, w) format
geometry_msgs/Pose base_link_pose

# Base velocity: [linear_x, linear_y, linear_z, angular_x, angular_y, angular_z]
float64[6] base_velocity

# Joint positions for 26 DOF (excluding 2 head joints)
# Sequence:
#   Motors 0-5:   Left leg (hip, hip, hip, knee, ankle, ankle)
#   Motors 6-11:  Right leg (hip, hip, hip, knee, ankle, ankle)
#   Motors 12-18: Left arm (shoulder, shoulder, shoulder, elbow, wrist, wrist, wrist)
#   Motors 19-25: Right arm (shoulder, shoulder, shoulder, elbow, wrist, wrist, wrist)
float64[26] joint_position

# Joint velocities for 26 DOF (excluding 2 head joints)
float64[26] joint_velocity

# End effector poses in world frame: [left_foot, right_foot, left_hand, right_hand]
geometry_msgs/Point[4] end_effector_poses
```

**（2）MOCAP 数据流**

MOCAP 重定后数据流通过一个话题进行发布（`/mocap/retargeted_pose`）
```c
# Base (root) pose in world frame
# Note: geometry_msgs/Pose.orientation is quaternion in (x, y, z, w) format
geometry_msgs/Pose base_link_pose

# Base velocity: [linear_x, linear_y, linear_z, angular_x, angular_y, angular_z]
float64[6] base_velocity

# Joint positions for 26 DOF (excluding 2 head joints)
# Sequence:
#   Motors 0-5:   Left leg (hip, hip, hip, knee, ankle, ankle)
#   Motors 6-11:  Right leg (hip, hip, hip, knee, ankle, ankle)
#   Motors 12:    Waist
#   Motors 13-19: Left arm (shoulder, shoulder, shoulder, elbow, wrist, wrist, wrist)
#   Motors 20-26: Right arm (shoulder, shoulder, shoulder, elbow, wrist, wrist, wrist)
float64[27] joint_position

# Joint velocities for 27 DOF (excluding 2 head joints)
float64[27] joint_velocity

# End effector poses in world frame: [left_foot, right_foot, left_hand, right_hand]
geometry_msgs/Point[4] end_effector_poses
```


## 重定向数据描述

0-1：高度信息
1-7：机身姿态 $2 \times 3$ 矩阵
7-13：机身速度（先线速度后角速度）
13-39：关节位置
39-65：关节速度
65-77：末端位置（4 x 3，世界坐标系）



# 算法实现

## 整体架构

VMP 算法部署在包含之前的离线轨迹播放功能的基础上，增加在线轨迹的播放功能
- 离线轨迹播放：支持特定轨迹的播放（单轨迹、多轨迹）
- 在线轨迹播放：
	- 支持提前录制的动捕数据的离线播放
	- 支持在线轨迹的播放


实现思路：
- 完成固定长度的环形缓存区的读写任务，可以通过在线导入离线的轨迹进行验证
- 完成话题的读取与预处理的测试，创建一个模拟话题发布的程序，给双臂发布正弦整理，VMP 控制器接收话题进行运动控制

## 输入输出

VMP 的输入包括三个部分
- 

## 缓存区

数据结构：固定长度的环形缓存区数据结构（FIFO 策略）
数据支持：
- Bin 格式的离线数据（可以先录一段时间的动捕设备数据进行播放，以验证算法的有效性
- VR 设备的在线数据
数据读写：
- **写入指针**：
	- 期望写入频率目前为 100 hz（受网络波动，频率会有变化）。
	- 写入指针从固定长度的一半开始写入，每次写入新帧后，写入指针前进 1 位
- **读取指针**：
	- 读取频率固定为 100 hz。
	- 读取指针从 0 帧开始读取，
		- 此时，假设固定长度为 200，历史帧 15 帧为环形缓存区的末尾数据（185-199），未来帧为环形缓存区 0 帧向后 14 帧的数据（1-14）
数据缓存 ：假设固定长度为 200，如果写入指针按照 100hz 的频率写入，则读取帧喝写入帧之前始终存在 100 帧的偏差，也就是为期 1s 的缓存。

## PICO 数据处理
VR 设备数据话题订阅 --- 数据预处理 --- 固定频率采样器


先拿一个话题进行模拟



### VR 读取获取




### 数据预处理



### 固定频率采样器


- 高度（线性插值）
- 机身姿态（6D ---> 四元数 --> **SLERP 插值** --> 6D）
- 机身速度（线性插值）
- 关节位置（线性插值）
- 关节速度（差分）
- 末端位置（根据世界坐标系下的位置差值后再根据关节位置做一个 FK）








数据集不是大小，对硬盘存储影响

8558 
cpu 主频
gpu 带宽



- 资源管理
- 数据清洗、标注
- 仿真平台（Isaac-gym）
