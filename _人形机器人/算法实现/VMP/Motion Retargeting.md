# 1. AMASS

## 概述
AMASS（**Archive of Motion Capture as Surface Shapes**）是一个**整合了多个 MoCap 数据集**的超大人体运动数据集，使用**SMPL 模型统一格式化表示**。

- 包含上百万帧高质量人体运动数据（来自真实MoCap系统）
- 所有数据都用 SMPL 参数（`θ`, `β`, `T`）重新拟合并表示
- 常见源数据集：CMU、HumanEva、MPI, BML, KIT等


## 数据形式


在 AMASS 的每一帧 `.npz` 文件中，典型地包含以下字段：

| 字段名             | 维度          | 含义                                     |
| --------------- | ----------- | -------------------------------------- |
| **poses**       | **\[N,72]** | 每帧的 SMPL 姿态参数（24 关节 × 3 轴角），关节空间的局部旋转。 |
| **betas**       | **\[10]**   | 体型参数（简化为前10个主成分）                       |
| **trans**       | **\[N, 3]** | 全身平移（root translation），笛卡尔空间的全局坐标      |
| gender          | string      | 通常为 "male", "female" 或 "neutral"       |
| mocap_framerate | int         | 动作捕捉的帧率，如 60fps                        |
| dmpls（可选）       | \[N, 8]     | DMPL 动态形状参数（可用于肌肉振动建模）                 |


>[! Note] AMASS 的 SMPL 描述
>- AMASS 不直接存储 6890 个网格点或 3D 关节坐标（这些太大）
>- 需要自己通过 SMPL 模型（代码或包）将 `poses`, `betas`, `trans` 转换为网格和关键点，即可恢复完整的网格/骨架


>[! Note] 使用轴角（axis-angle）格式表示姿态
>轴角表示法用一个**单位向量** $\mathbf{n} \in \mathbb{R}^3$（旋转轴）和一个**旋转角度** $\theta$ 来描述一个三维旋转。
我们通常将其表示为一个 3D 向量：
$$\mathbf{r} = \theta \cdot \mathbf{n} \in \mathbb{R}^3$$
>- 向量 $\mathbf{r} = [0, 0, \pi]$ 表示围绕 Z 轴旋转 180°。
>- SMPL 中就是用这种方式来描述每个关节的旋转：24 个关节 × 3 D 轴角 = 72 维姿态向量。
>- 没有直接提供姿态旋转矩阵或四元数, 使用时需要先转换为旋转矩阵再输入 SMPL 模型


# 2. SMPL

## 概述
SMPL（**Skinned Multi-Person Linear**）是一个**参数化的三维人体网格模型**，它使用少量的形状和姿态参数来表示任意人的3D身体形态与动作。它的核心思想是将人体建模为一个具有以下特征的参数化网格：


- **输入参数**：
    - $\beta$（shape）：描述体型（如高矮胖瘦）
    - $\theta$（pose）：描述姿态（24个关节的旋转）
    - $T$（global translation）：身体在世界中的平移
- **输出**：6890 个顶点的三维网格（可用于可视化、动画、重建）
- **优点**：可微、兼容骨骼动画系统、与真实扫描数据匹配

## 参数描述
SMPL 模型确实既包含了关节空间的参数，也包含了笛卡尔空间的参数。我们可以更清晰地从两个空间的角度来理解：

### 关节空间参数

这是 SMPL 的核心输入参数之一，用于控制人体的**姿态（Pose，$\theta$）**，即关节如何旋转：

- 表示 **24个关节的旋转**
- 每个关节的旋转用 **轴-角（axis-angle）形式**表示（也可用旋转矩阵或四元数）
- 共计 **24 × 3 = 72维** 的姿态向量
- 属于典型的**关节空间表示**（即关节的角度/姿态）

此外，SMPL内部也构建了一套骨骼层级结构（kintree），用于确定每个关节的父子关系并正确传播关节旋转（Forward Kinematics）。

---

### 笛卡尔空间参数

这些参数直接描述的是**人体网格或关节在三维空间中的位置**，例如：

 ***1. 顶点位置 `V`***

- 最终输出的 6890 个顶点坐标
- 每个顶点是 3D 空间中的 $(x, y, z)$ 坐标
- 这是**笛卡尔空间中最直接的表达**
    

***2. 关节位置 `J`***

- 由回归器 `J_regressor` 从网格顶点线性回归获得
- 表示 24 个关节在 3D 空间中的坐标（`J ∈ ℝ^{24×3}`）
- 用于计算 3D关键点位置、姿态估计误差、人体骨架等

***3. Global translation `T`***

- 有时也作为输入参数之一
- 控制整个身体在世界坐标系中的位置（例如将人物平移到地面上）

---

|类型|参数|描述|所属空间|
|---|---|---|---|
|姿态参数|`θ`|关节的轴角/旋转矩阵|**关节空间**|
|全身平移|`T`|身体在世界坐标中的位置|**笛卡尔空间**|
|顶点坐标|`V`|网格点的 $(x,y,z)$ 位置|**笛卡尔空间**|
|关节坐标|`J`|每个关节的 3D 位置|**笛卡尔空间**|
|骨架结构|`kintree_table`|关节拓扑结构（父子关系）|**关节空间结构**|

---

## SMPL 模型变体

| 模型         | 基于      | 支持部位      | 特点与用途                                 |
| ---------- | ------- | --------- | ------------------------------------- |
| **SMPL-H** | SMPL    | + 手部      | 为双手加上详细的 15 关节 × 2 = 30 个关节；用于手势捕捉    |
| **SMPL-X** | SMPL-H  | + 面部 + 眼睛 | 最全面的人体建模模型：手+脸+眼；用于虚拟人、情感识别等          |
| **MANO**   | SMPL-H  | 手部（仅手）    | 高精度手部建模（15关节）；适用于单手追踪、手势识别            |
| **FLAME**  | 独立开发    | 面部（仅面）    | 高精度面部建模；适用于面部动画、表情重建                  |
| **SMIL**   | SMPL    | 儿童身体      | 专门为儿童设计的体型参数模型                        |
| **SMAL**   | 改进SMPL  | 四足动物      | 支持动物如狗、猫、马等的3D建模                      |
| **STAR**   | 精简版SMPL | 成人        | 模型参数简化，适合大规模计算；常用于效率要求高的场景            |
| **GHUM**   | 非SMPL系  | 全身+手+面    | 高保真多分辨率模型；在Neural Body领域中常用（如VIBE等模型） |



# 3. 重定向方法

## 直接映射法

对人体参考数据和目标机器人的建立一一对应关系，无需额外的外部优化库。
- 将人体关节的旋转角度直接映射到机器人关节
- 对于维度不匹配的情况（如人体 3 Dof 关节映射到机器人 1 Dof 关节），可以选择特定的轴进行映射。

**优点：**
- 实现简单，无需复杂优化
- 可以支持不同坐标系的转换。即将不同标准的坐标系之间数据转换成统一形式（坐标轴交换、平移向量的转换、四元数的矩阵变换）。
- 支持旋转表示转换。即将轴角 SO3 旋转向量转换为四元数表示


**缺点：**
- 不考虑物理约束和自然度优化
- 缺乏碰撞检测和自平衡调整
- 关节限制处理相对简单


## 基于逆运动学的运动重定向

AMASS 模型提供了人体运动的关键点位置（`xpos`）和旋转矩阵（`xmat`），对于目标机器人，需要通过**逆运动学**调整关节配置，使其运动与 AMASS 模型的运动一致。逆运动学的部分主要基于 `mink`库进行实现。

---

1. **AMASS 数据加载与解析：**
	-  提取姿态参数`poses`（根节点、身体节点、手部节点等），并将轴角转换为四元数或旋转矩阵形式，以便用于关节的姿态表示。
	- 提取全局位置参数`trans`，用以初始化目标机器人模型的基体位置
	- 提取帧率信息`mocap_framerate`
	- 
2. **初始化机器人模型和场景模型**
	- 机器人模型作为目标模型，用于接收从 SMPL 模型映射过来的运动数据
	- SMPL 模型缩放：
		- *全局缩放*：根据目标模型身高和 SMPL 模型的身高（肩膀到脚踝）计算缩放比例 `scale`，直接对`vertices`和`bones`进行直接缩放；
		- 
		- *帧率对齐*：根据物理学相似性定律特性，时间与长度的平方根成正比:$t_2/t_1 = np.sqrt(L2/L1)$，也就是说当物体尺寸缩小时，相同的运动应该需要更短的时间，从而实现空间和时间的一致性。
	- 场景模型用于提供一个可视化环境，用于对比和验证运动重定向的效果。

3. **任务定义：姿态任务和帧任务。**
	- 定义一个全局姿态任务：用以保持机器人模型的整体姿态，避免某些关节以满足局部关键点的对齐，从而忽略整体的运动流畅性。
		- *脚部对齐*：将机器人整体 z 方向平移，是机器人脚底高度与 SMPL 脚底高度对齐。
		- *关键点偏移计算*：计算两个模型之间关键点的相对位置偏移，后续机器人`site`的初始位置就是机器人 body 原地+ 对应关键点偏移来对齐的。后续这个偏差一直存在，是 `site` 的局部坐标系。

	- 定义帧任务：用于将机器人的关键点对齐到 SMPL 模型的关键点的位置和方向。每个帧包括：基体任务、腿部任务、脚部任务、手臂任务、手部任务、手指任务。

4. **计算 SMPL 模型的关键点位置和方向** 
	遍历每一帧
	-  将当前帧下 SMPL 模型的关节位置 `qpos`数据
	- 通过 `mujoco.mj_forward` 计算前向动力学，提取 AMASS 模型关键点数据
		- 关键点的全局位置`smpl_xposs`：(nframes, n_keypoints, 3)
		- 关键点的方向矩阵`smpl_xmats`： (nframes, n_keypoints, 3, 3)

5. **任务目标设定和逆运动学求解**
	遍历每一帧
	- **设置目标**：
		- *全局姿态任务*：使用目标机器人的当前的关节位置作为目标，这样保证机器人的整体姿态尽量保持稳定
		- *帧任务*：遍历所有需要对齐的关键点，将 SMPL 模型的关键点位置和方向作为位姿目标。
			- `mink.SO3.from_matrix`：将方向矩阵转换为的旋转对象（so 3 轴角形式）
			- `mink.SE3.from_rotation_and_translation`：将旋转对象和位置组成一个完整的位姿对象。
	- **逆运动学求解**：
		- 根据帧任务中设定 SMPL 位姿，调用 `mink.solve_ik` 求解逆运动学，得到机器人的期望关节速度。
		- 调用`integrate_inplace` 将速度积分到关节位置
		- 通过不断更新机器人模型的关节位置，使其逐帧逼近 AMASS 模型的运动，并记录这个过程中机器人的关节位置。
		- 注：在第一帧时，为了保持初始状态的稳定，会多次迭代求解逆运动学。


>[! WARNING] AMASS 数据集的全局缩放
> 在机器人运动重定向初始过程中，为后续方便跟踪，初始时需要将 SMPL 的关键点和机器人的关键点在一个特定状态下进行对齐，获得机器人初始`site`。
> 后面，机器人运动过程中需要跟踪 SMPL 的每一帧关键点位姿：
> - 如果未根据机身高度去缩放 AMASS 数据集的关键点，机器人在运动过程中跟踪的目标点就有可能存在较大误差，且机器人`site`的偏置误差也是根据缩放机器人设置的；因为高度没有变化此时帧率也不需要进行调整。
> - 如果根据机身高度进行缩放，则会和初始阶段进行对齐，但是直接根据高度进行缩放的合理性需要验证，同时为了时间一致性帧率也需要调整。如果数据集中出现高度不一致的情况，则需要对整个数据集的帧率进行对齐。
> 


## OmniH2O 运动重定向

OmniH2O 重定向共包含两个过程：形状拟合优化和关节动作重定向。先优化形状，在优化动作，降低问题的复杂度。这两个过程都采用**梯度下降**的方法进行位置差异进行优化。

- **形状拟合优化** ：优化 SMPL 模型的形状参数和缩放因子，使得 SMPL 模型的位姿尽可能接近目标机器人的位姿。
- **动作重定向优化**：将 AMASS 数据集中的人体动作序列转换为机器人可执行的关节角度序列。

--- 
***形状拟合优化***：
1. **预处理**
	 - 定义 SMPL 模型和机器人之间关节的对应关系
	 - 为 SMPL 模型设置一个初始标准姿态（T-pose、A-pose）
	 - 初始化待优化的形状参数和缩放因子
2. **策略优化**：
	- 优化的变量：SMPL 的形状参数和缩放因子
	- 目标函数： SMPL 模型位姿和机器人位姿的欧几里得距离 （需要进行前向运动学转换）
	- 优化方法：Adam 对形状参数和缩放因子进行调整。

>[! Note] 
>在整个优化过程中，机器人的姿态是固定的（标准站立姿态），SMPL 模型的关节位置会通过形状参数优化逐渐接近机器人的关节位置。即机器人仅需进行一次前向运动学计算即可，SMPL 模型则需要进行多次。



--- 
***动作重定向优化***：

1. **预处理**：
	- 加载 AMASS 人体动作数据
	- 加载之前优化好的 SMPL 形状参数
	- 定义关节映射关系
2. **姿态转换**：将人体关节旋转映射到机器人的单轴旋转系统（关节空间映射）
3. **策略优化**：
	- 优化变量：机器人的关节角度
	- 目标函数：最小化SMPL 模型位姿和机器人位姿的欧几里得距离
	- 优化方法：采用 Adadelat 优化器调整机器人关节的角度
	- 约束条件：应用关节限制，确保生成的动作在机器人物理能力范围内
4. **动作处理：**
	- 数据采样：将动作数据降采样到 30 fps 以提高处理效率
	- 根节点处理：特别处理根节点旋转和平移，确保动作流畅
	- 地面接触：调整根节点高度避免穿透地面

两过程对比：

| 方法   | 形状拟合优化                      | 动作重定向优化             |
| ---- | --------------------------- | ------------------- |
| 优化变量 | SMPL形状参数（10 dim）和缩放因子（1dim） | 机器人的关节角度（关节自由度\*帧数） |
| 优化器  | Adam（lr=0.1）                | Adadelta（lr=100）    |
| 迭代次数 | 100                         | 1000                |
| 特殊处理 | 无                           | 关节角度限制              |
| 数据维度 | 静态姿态（T-pose）                | 时序动作序列              |


## 总结

-  OmniH2O 方法目标损失函数仅考虑位置的跟踪误差，并未体现出姿态方面的跟踪误差，因此 OmniH2O 在位置方面的跟踪精度会比较高，但是对姿态部分的精度在有些轨迹中跟踪的就会比较大。
- IK 的方法中，在求解过程中同时考虑了关键点的位置和姿态，且可以通过权重调整位置和姿态的重视程度，所以重定后的动作会整体会更接近源数据。



# 运动重定向可行性过滤

## MPC 轨迹优化


## RL 模仿学习

通过特权教师策略//Mimic 算对重定向的数据进行模仿，进


# 运动重定向评价标准


## 运动学评价

### 关键点距离误差
衡量：重定向后机器人身体各关键点与原始人类动作对应点之间的欧氏距离。
公式：
$$
    \text{Position Error} = \frac{1}{T} \sum_{t=1}^T \frac{1}{N} \sum_{i=1}^N \| p_i^{(t)} - \hat{p}_i^{(t)} \|_2
$$
-  $p_i^{(t)}$ 是目标机器人在时刻 $t$ 的第 $i$ 个关键点
- $\hat{p}_i^{(t)}$ 是原始动作中的对应点。


### 关键点方向误差

 ***1. 使用旋转矩阵计算角误差***

- 每个关节姿态（orientation）以 **旋转矩阵 $R \in \mathbb{R}^{3\times3}$** 表示。
- 需要比较预测值 $R_{\text{pred}}$ 和参考值 $R_{\text{ref}}$ 之间的“角度差异”。

1. 计算两个旋转矩阵的**相对旋转矩阵**：
$$R_{\text{rel}} = R_{\text{pred}} R_{\text{ref}}^\top$$
2. 从相对旋转矩阵中提取旋转角度 $\theta$（轴角中的角）：
$$\theta = \arccos\left(\frac{\text{trace}(R_{\text{rel}}) - 1}{2} \right)$$
- $\theta$ 就是从参考姿态旋转到预测姿态所需的最小旋转角度。
- 数值范围是 $[0, \pi]$，单位是弧度。


---

***2. 使用四元数计算角误差***

- 每个关节姿态以**单位四元数** $q = [w, x, y, z]^\top$ 表示。
- 需要比较预测四元数 $q_{\text{pred}}$ 和参考四元数 $q_{\text{ref}}$ 的差异。

1. **归一化**两个四元数（如果不是单位四元数，单位四元数的长度（模）是 1）
2. 计算两个四元数的点积（内积）：
$$d = | \langle q_{\text{pred}}, q_{\text{ref}} \rangle | = | w_1 w_2 + x_1 x_2 + y_1 y_2 + z_1 z_2 |$$
    这里取绝对值是因为 $q$ 和 $-q$ 表示相同的旋转。
3. 转换为角度（单位：弧度）：
$$\theta = 2 \cdot \arccos(d)$$

- 结果 $\theta \in [0, \pi]$，表示两个方向之间的**最小旋转角**。
- 可将其乘以 $\frac{180}{\pi}$ 转换为角度。


***3. 使用 Frobenius 范数计算误差

对于一个矩阵 $A \in \mathbb{R}^{n \times n}$，Frobenius 范数定义为：

$$\|A\|_F = \sqrt{ \sum_{i=1}^{n} \sum_{j=1}^{n} |a_{ij}|^2 } = \sqrt{\text{trace}(A^\top A)}$$
- **迹（trace）** 是线性：代数中的一个概念，表示一个方阵的**主对角线**元素的和。
--- 

假设
- $R_1$ 是参考（ground-truth）旋转矩阵
- $R_2$ 是预测旋转矩阵

我们可以通过它们之间的差的 Frobenius 范数来度量误差：

 **方式 1：直接差值范数（直观差异）**

$$\text{Error}_{\text{Fro}} = \| R_1 - R_2 \|_F$$​
- 取值范围：$[0, 2\sqrt{3}]$（最大误差为两个旋转方向完全相反时）
- 优点：直观、简单、常用于监督损失

---

**方式 2：基于相对旋转的 F-norm（具有几何意义）**

从几何上更合理的方法是，计算**相对旋转矩阵**与单位矩阵的 Frobenius 距离：
$$\text{Error}_{\text{FroRel}} = \| I - R_{\text{rel}} \|_F = \| I - R_1^\top R_2 \|_F$$​
- 其中 $R_{\text{rel}} = R_1^\top R_2$ 是将 $R_1$ 旋转到 $R_2$ 所需的变换。
- 当 $R_1 = R_2$ 时，误差为 0。

---

 **Frobenius 范数与角误差的关系**

Frobenius 范数和角度误差 $\theta$ 存在明确关系：
$$\|R_1 - R_2\|_F^2 = 8 \sin^2\left(\frac{\theta}{2}\right)$$
因此可以反推角度：
$$\theta = 2 \arcsin\left(\frac{1}{2\sqrt{2}} \|R_1 - R_2\|_F \right)$$

## 动力学评价

### 速度平滑性

***1. 关键点速度*** -- 
- **作用**：动作还原的自然性与流畅性，常用于 SMPL 动作、AMASS 数据等重定向到机器人身上，希望保留人的运动节奏。
- 评估指标如：
$$\text{Velocity Error} = \frac{1}{T} \sum_{t=1}^T \| \dot{p}_t^{\text{ref}} - \dot{p}_t^{\text{retarget}} \|_2
$$
其中 $p_t$ 是关键点的位置，$\dot{p}_t$ 是其速度。

***2. 关节速度平滑性*** 

- **作用**：控制稳定性或机器人硬件执行可行性。
- 评估指标如：
    - **速度平滑性（Smoothness）**：计算关节速度的时间变化率（即加速度），例如 jerk（加加速度）。
    - **连续性指标**可能是 $\dot{q}_t$ 或 $\ddot{q}_t$ 的变化范数。 $$\text{Smoothness} = \frac{1}{T-1} \sum_{t=2}^{T} \| \dot{q}_t - \dot{q}_{t-1} \|_2^2$$​