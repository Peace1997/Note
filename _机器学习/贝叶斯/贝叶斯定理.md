# 一、先导

## 联合概率分布

对于离散随机变量，P (X, Y) 是 X, Y 同时发生的概率
> 注：P (X, Y) 也可写为 P (X=x, Y=y)

若 X 和 Y 相互独立，则 P (X, Y) = P (X) * P (Y)
若 X 和 Y 不相互独立，则 P (X, Y) = P (Y|X) * P (X)=P (X|Y) * P (Y)


## 条件概率 

$$
P(Y \mid X) = \frac{P(X,Y)}{P(X)}
$$
X、Y 不相互独立

## 先验概率
又称边缘概率

通常根据统计或自身依据经验给出的一个概率，即先验概率是对某一件事情发生可能性的预先客观评估。 —— [[常用解释#先验概率 & 后验概率]]

$$
P(X=x) = \sum\limits_{y}P(X=x\mid Y=y)P(Y=y)
$$


# 二、贝叶斯定理

描述在已知条件下，某事件的发生概率。用来描述两个条件概率之间的关系。
$$
P(Y \mid X)= \frac{P(X,Y)}{P(X)}=\frac{P(X \mid Y) P(Y)}{P(X)}
$$
> 由联合概率分布，X 和 Y 不相互独立推导而来

根据先验概率展开：
$$
P(Y_{i}\mid X) = \frac{P(X \mid Y_{i}) P(Y_i)}{\sum_\limits{j}^{n} P(X\mid Y_j)P(Y_j)}
$$
展开为：
$$
P(Y=y_i \mid X=x)=\frac{P(X=x \mid Y=y_{i}) P(Y=y_i) }{\sum_\limits{j}^{n} P(X=x \mid Y=y_{j}) P(Y = y_{j}) }= \frac{P(X=x \mid Y=y_{i}) P(Y=y_i)}{P(X=x \mid Y = y_{1})P(Y=y_{1})+\ldots +P(X=x \mid Y=y_{n})  P(Y=y_{n}) }
$$






























## 朴素贝叶斯
朴素贝叶斯（naive Bayes）是基于贝叶斯定理与特征条件独立假设的分类方法。

**总体过程**：
- 根据给定的训练数据集，基于特征条件独立假设 学习输入输出联合概率分布P(X,Y)
- 对给定输入x，利用贝叶斯定理求出后验概率分布P(Y | X)


**数学建模：**
- 给定训练数据集：
$$
T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
$$
- 利用训练数据集学习先验概率分布$P(Y)$及条件概率分布$P(X | Y)$，然后得到联合概率分布
$$
P(X,Y) = P(Y)P(X|Y)
$$
- 然后选用极大似然估计或贝叶斯估计作为概率估计方法

条件独立性
