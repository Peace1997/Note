## 任务完成
- 基于 Ray  RLlib 与编队控制环境进行预训练测试，设置各项训练初始条件，完成自建编队控制环境注册，设置编队控制任务的结束条件，并完成训练数据的可视化展示和模型的定期保存等
- 学习 Ray 2.9.3 官方参考文档，初步调用 Ray Tune 进行超参数优化

利用 Tensorboard 对训练结果进行可视化：
![[Pasted image 20240308180500.png]]

调用 Ray Tune 对计算资源和训练数据进行展示。
![[Pasted image 20240308181023.png|400]]
![[Pasted image 20240308180420.png]]

## 下周安排
- 继续进行调参训练，配合 Ray 的 Tune 对相关超参数优化，继续学习 Ray 的相关内容
- 自定义 logger 来获取环境的输出信息，并对相关训练数据进行保存
- 在训练过程中进行阶段性测试，评估智能体的性能,及时发现和修复问题，并适时对交互环境进行可视化展示
- 了解 RLlib 下的 PPO 算法运行机制，并根据需要对策略网络模型结构进行重写
- 参考 Ray 官方文档对运行过程中出现的错误和警告进行分析修正
