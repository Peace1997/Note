# Alpha Go

—— 包括AlphaGo Zero和AlphaZero

AlphaGo 的算法主要分为两部分：
- 一部分是通过神经网络拟合一个可以评估和预测的模型；
- 结合这些独立算法，通过搜索树的策略来增强这个模型的性能。
-
## 训练
通过策略网络来选择如何下棋落子，同时使用值函数网络来评估得到的棋局的好换程度。在训练过程中，首先使用人类专业比赛的数据进行监督学习，训练得到一个策略网络；使用该参数对强化学习的网络参数初始化，接下来在自我对弈中进行强化学习。

> 在没有使用任何预测搜索方法的时候，其性能已经达到了最先进的蒙特卡洛搜索树的水准

## 搜索

引入了一种新的搜索算法， 该算法把蒙特卡洛（MTCS）和估值、策略网络集合在一起。

DQN关系
# 