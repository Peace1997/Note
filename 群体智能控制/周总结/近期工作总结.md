![[群体智能控制/周总结/img/学习内容总结.png]]
**任务要求**：构建一个简化的飞行器仿真训练环境(不要求可视化)，能驱动智能算法进行训练，定义好输入输出，以多机编队或者协同制导任务进行算法的研究。
**计划安排**：整体任务分为两个阶段完成：
- 第一阶段的任务是：控制单个导弹，从某个起始点出发，到达相应的目标点;
- 第二阶段的任务是：加入多个导弹，在单个火箭基础上，协调多个导弹同时到达同一目标点。

# 一、基础知识的学习
- 阅读协同制导和编队控制的相关论文，了解整个任务的要求和目标，并总结了关键技术和方法，
- 学习了导弹力学的基础知识，包括四种坐标系、坐标系角度定义和转换关系以及导弹动力学方程的推导。
# 二、仿真平台的调研及RLlib框架搭建
- 对导弹/飞行器的物理仿真平台进行调研，并通过学习强化学习在导弹中的应用的论文和开源项目，对相应项目进行了复现。最终 选用了 Box2D 作为当前的仿真环境，并将 Lunarlander 项目为基准。
- 选用RLlib作为强化学习训练框架；搭建RLlib所需要的依赖，并测试Lunarlander的相关项目
- 为了方便日后的环境迁移，基于 Docker 制作了相应的 Image 环境

# 三、单导弹环境制导任务实现
- **任务目标**：导弹头部与目标区域地面发生碰撞
- 以 Lunarlander 项目为基准，修改了导弹构型、地面环境以及碰撞检测等规则
- 根据设定的任务要求，设计单个导弹的MDP模型
- 根据 Gymnasium 和 RLlib 的编码规范实现智能体与环境的交互过程
- 为提升训练效果设计了两种训练策略：
	- **端到端的运动控制**：通过深度强化学习方法直接控制导弹的推进器
	- **PID控制与RL的联合运动控制**：将PID控制器的动作输出作为基准动作，深度强化学习在此动作基础上进行微调，即在PID控制基础上叠加RL修正动作。
- 接下来不断训练调参，每次训练随机初始化每个智能体和目标点的位置，经训练，目前单智能体头部与目标区域地面发生碰撞的成功率大于 90%，但精准制导的成功率只有 65%左右。

不同起始位置和不同目标点位置 任务完成关键帧：
![[Pasted image 20230611105824.png|400]]
![[Pasted image 20230611105844.png|400]]
![[Pasted image 20230611110200.png|400]]
![[Pasted image 20230625162057.png|400]]

# 四、多导弹环境制导任务实现
-  **任务目标**：在一定时间阈值内，所有智能体到达同一目标区域。
- 在单导弹环境基础上，进行多导弹环境的修改，可以支持任意数量导弹的导入
- 将多智能体的目标决策建模为 Dec-POMDP，每个智能体基于对环境的局部感知以及相互之间的部分信息共享, 独立进行目标点决策。设计每个智能体 POMDP 模型。
- 参照 Gymnasium 以及 RLLib 多体交互案例实现多导弹与环境的交互

仅使用PID控制器对多导弹控制的环境测试
![[Pasted image 20230702170602.png|400]]