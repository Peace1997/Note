# 概念解释

## 伯努力分布 & 二项式分布 & 多项式分布
### 伯努利分布：
伯努利分布（the Bernoulli distribution，又名两点分布或者 0-1 分布，是一个离散型概率分布），若伯努利试验成功，则伯努利随机变量取值为 1。若伯努利试验失败，则伯努利随机变量取值为 0。记其成功概率为 p ($0 \leq p \leq 1$)，则失败概率为 q = 1 − p。
其概率质量函数为:
$$f_{X}(x)=p^{x}(1-p)^{1-x}= \begin{cases}p & \text { if } x=1, \\ q & \text { if } x=0 .\end{cases}$$
伯努力分布的模型参数就是其中**一个类别的发生概率**。

### 二项式分布：
就是将贝努利实验重复n次（各次实验之间是相互独立的）

### 多项式分布：
将二项式分布推广到多个类别，所以单词观测下的多项式分布就是伯努利分布的多类别推广，多项式分布的模型参数就是**各个类别的发生概率**。
$$
f_{\text {multi }}(x ; p)=\prod_{i=1}^{C} p_{i}^{x i}
$$
> $C$表示类别数；$p$ 表示向量形式的模型参数，即各个类别的发生概率，如：$p=[0.1,0.1,0.7,0.1]$。$x$表示one-hot类型的观测值，如 $x=$ 类别3 则表示为 $x=[0,0,1,0]$ 
> 扩展到机器学习的分类问题中，一个分类模型对某个样本的输出，就代表着各个类别发生的概率，但是**对于一个样本（观测）来说，只有一个类别** ，这次观测的结果要服从上述各个类别的发生概率，也就是要服从多项式分布，所以各个类别的发生的概率 predict 自然就是这个多项式分布的参数。

## 熵 & 交叉熵
### 熵
熵是服从某一特定概率分布事件的理论最小平均编码长度。
$$
H(P)=\text { Entropy }=\mathbb{E}_{x \sim P}[-\log P(x)]
$$

已知离散变量 $i$ 的概率分布$P(i)$，熵的公式为：$Entropy =-\sum_{i} P(i) \log _{2} P(i)$
已知连续变量 $x$ 的概率分布 $P(x)$，熵的公式为：$Entropy =-\int_{x} P(x) \log _{2} P(x)$

只要我们知道了任何事件的概率分布，我们就可以计算它的熵；那如果我们不知道事件的概率分布，又想计算熵，就需要交叉熵来完成。

### 交叉熵
**熵的估计**
我们用预估的概率分布Q，可以计算估计的熵
$$
H(Q)=\text { Estimated\_Entropy }=\mathbb{E}_{x \sim Q}[-\log Q(x)]
$$
-   计算期望的概率分布是Q，与真实的概率分布P不同。
-   计算最小编码长度的概率是 -logQ，与真实的最小编码长度 -logP 不同。

**交叉熵**
交叉熵使用H(P,Q)表示，意味着使用P计算期望，使用Q计算编码长度；这样实际编码长度和理论最小编码长度就有了对比的意义。
$$
 \text { CrossEntropy }=H(P,Q) =\mathbb{E}_{x \sim P}[-\log Q(x)]
$$
对于期望，我们使用真实概率分布P来计算；对于编码长度，我们使用假设的概率分布Q来计算，因为它是预估用于编码信息的。因为熵是理论上的平均最小编码长度，所以交叉熵只可能大于等于熵。
>H(P,Q)并不一定等于H(Q,P)，除了在P=Q的情况下，H(P,Q) = H(Q,P) = H(P)。

**交叉熵作为损失函数**
交叉熵通常用作分类问题的损失函数。
这时 P 为真实每个标签概率（\[1, 0, 0]；因为通常最后分类结果只有一个）
Q 为模型预测的的每个标签概率（\[0.6, 0.1, 0.3]；对各个类别的预测）
此时就可以通过交叉熵来对比模型预测结果和数据的真实标签，随着预测越来越准确，交叉熵的值越来越小。如果预测完全正确，交叉熵的值就为0


 
 https://zhuanlan.zhihu.com/p/149186719


## 似然函数 & 极大似然估计
### 似然函数（likelihood）
对于多类分类问题，似然函数就是衡量当前这个以predict为参数的单次观测下的多项式分布模型与样本值label之间的似然度。

### 极大似然估计
利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。
>极大似然的核心思想是如果现有样本可以代表总体，那么**极大似然估计就是找到一组参数使得出现现有样本的可能性最大。**
>简单来说就是**根据数据推测模型**。

==模型主要指的就是这些**特定的算法下的特定的参数的组合**==


极大似然估计中采样需满足一个重要的假设，就是所有的采样都是**独立同分布**的。

应用场景：样本太多，无法得出分布的参数值，可以采样小样本后，利用极大似然估计获取假设中分布的参数值。
**极大似然估计思想在强化学习中的应用**：
在策略梯度神经网络更新时，首先从经验回放池中采样出一批数据，这批数据有好有坏（好坏有该状态下对应的价值评定），我们希望好的数据出现的概率大一些，因此就需要调整模型的参数，即根据采样出来的样本集，反推出能使好数据出现概率更高的模型参数。

#极大似然估计 
## 全概率公式 & 贝叶斯公式
根据时间顺序，先发生的是A，后发生的是B；求B就用全概率公式；求A就用贝叶斯公式（路径概率）
### 全概率公式: 
$$\quad P(B)=P\left(A_{1}\right) P\left(B \mid A_{1}\right)+P\left(A_{2}\right) P\left(B \mid A_{2}\right)+\ldots+P\left(A_{n}\right) P\left(B \mid A_{n}\right)$$
### 贝叶斯公式:
$$
P\left(A_{i} \mid B\right)=\frac{P\left(A_{i}\right) P\left(B \mid A_{i}\right)}{\sum_{j=1}^{n} P\left(A_{j}\right) P\left(B \mid A_{j}\right)}=\frac{P\left(A_{i}\right) P\left(B \mid A_{i}\right)}{P\left(A_{1}\right) P\left(B \mid A_{1}\right)+\ldots+P\left(A_{n}\right) P\left(B \mid A_{n}\right)}
$$



## 先验概率 & 后验概率

### 先验概率
根据统计或自身依据经验给出的一个**概率**，即先验概率是对某一件事情发生可能性的预先客观评估。

### 后验概率
在考虑和给出相关证据或数据后所得到的**条件概率**。而后验概率是对事情发生是由某一个原因导致的概率。

> [先验概率](https://zh.m.wikipedia.org/zh-hans/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87)通常是主观的猜测，为了使计算后验概率方便。在使用[贝叶斯定理](https://zh.m.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86 "贝叶斯定理")时，我们通过将先验概率与[似然函数](https://zh.m.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0 "似然函数")相乘，随后标准化，来得到[后验概率](https://zh.m.wikipedia.org/wiki/%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87 "后验概率")分布
> 概率和条件概率简单的区别是有无限制条件：如 P(A) 为概率，P(A|B)为条件概率



先验概率是 以全事件为背景下,A事件发生的概率，P(A|Ω)
后验概率是 以新事件B为背景下,A事件发生的概率， P(A|B)

全事件一般是统计获得的，所以称为先验概率，没有实验前的概率
新事件一般是实验，如实验B，此时的事件背景从全事件变成了B，该事件B可能对A的概率有影响，那么需要对A现在的概率进行一个修正，从P(A|Ω)变成 P(A|B)，

所以称 P(A|B)为后验概率，也就是试验(事件B发生)后的概率

**举例**：
https://zhuanlan.zhihu.com/p/26464206
已知：
	- P ($A_1$) = 0.6  、 P ($A_2$) =0.4   —— 先验概率
	- P ($B_1$ | $A_1$) = 0.8  、P ($B_2$ | $A_1$) = 0.2  、 P ($B_2$ | $A_2$) = 0.8 、 P ($B_2$ | $A_2$) = 0.2  —— 条件概率
求：已知在事件 $B_1$ 的基础上，事件 $A_1$ 发生的概率
解：利用贝叶斯公式
$$
P(A_1 | B_1) = \frac{P(A_1)P(B_1|A_1)}{P(A_1)P(B_1|A_1) + P(A_2)P(B_1|A_2)}
$$
我认为整个计算过程可以分为两块，
- 先计算$B_1$发生的概率：所以需要先计算$B_1$发生的概率：$\frac{P(B_1|A_1)}{P(A_1)P(B_1|A_1) + P(A_2)P(B_1|A_2)}$
- 然后在计算在 $B_1$ 发生的基础上 $A_1$ 发生的概率
> 如果没有说在$B_1$基础上$A_1$发生的概率的话，就可以直接得出$A_1$发生的概率：$P(A_1)$

因此有无计算B事件基础上发生A事件的概率，是先验概率和后验概率的区别。在B事件基础上发生A则为

#后验概率 #贝叶斯公式

## 凸性

https://zh.d2l.ai/chapter_optimization/convexity.html


## KL 散度
用来衡量两个分布的相似程度


## 独立同分布

定义：是指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立。

并非所有机器学习模型的必然要求（比如 Naive Bayes 模型就建立在特征彼此独立的基础之上，而Logistic Regression 、神经网络则在非独立的特征数据上依然可以训练出很好的模型，比如使用LR拟合用户收入，会使用很多相关联的特征，这里就不要求特征之间是独立同分布），但独立同分布的数据可以简化常规机器学习模型的训练、提升机器学习模型的预测能力，已经是一个共识



## 源空间 & 目标空间

* **源空间（source domain）**：表示与测试样本不同的领域，但是有丰富的监督信息；
* **目标空间（target domain）**：表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同。

在经典的机器学习问题中，一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”，即我们往往假设训练集和测试集分布一致，在训练集上训练模型，在测试集上测试，如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。

以人脸识别为例，如果用东方人人脸数据训练，用于识别西方人，相比东方人识别性能会明显下降。当训练集和测试集分布不一致的情况下，通过在训练数据上按经验误差最小准则训练的模型在测试上性能不好，因此出现了迁移学习等技术。

https://www.cnblogs.com/ying-chease/p/13846413.html

## 均值和期望

平均数是一个统计学概念，期望是一个概率论概念。

**平均数是实验后根据实际结果统计得到的样本的平均值，期望是实验前根据概率分布“预测”的样本的平均值。**

> 之所以说“预测”是因为在实验前能得到的期望与实际实验得到的样本的平均数总会不可避免地存在偏差，毕竟随机实验的结果永远充满着不确定性。如果我们能进行无穷次随机实验并计算出其样本的平均数的话，那么这个平均数其实就是期望。当然实际上根本不可能进行无穷次实验，但是实验样本的平均数会随着实验样本的增多越来越接近期望，就像频率随着实验样本的增多会越来越接近概率一样。

如果说概率是频率随样本趋于无穷的极限，那么期望就是平均数随样本趋于无穷的极限。


## 对数概率

为什么要计算概率后取对数？
- 首先log是单调函数（不改变极值的位置）
- 
