

# 一、低数据量方法

***基本思想***：
使用刚体动力学模型 + 域随机化方法。
依赖现有的刚体动力学模型，通过在仿真中随机化或小幅调整模型参数，使在仿真中训练的策略对真实世界参数不确定性方法具备鲁棒性，从而尽量少用真实数据。


***常见方法***：
- **Cassie SysID + Domain Randomization** ： 通过系统辨识获得近似参数，然后在训练过程中对质量、摩擦、阻尼等参数随机化。
- **Hand-calibrated parameters + Randomization**：先人工校准，然后在训练中施加扰动。
- **Active/Adversarial domain randomization**：随机化不是均匀采样，而是通过对抗优化选择最能暴露模型不足的参数（如 BayesSim、DROPO）。
- **DexTreme (for manipulation)**：通过大规模参数扰动提升 dexterous hand 的鲁棒性

***评价***：
- 所需真实数据少，实现简单，易于并行化
- 大量随机化会导致策略过于保守或难以收敛
- 随机化空间往往取决于经验性，需要人工调整


# 二、中等数据方法

***核心思想***

- 在物理先验（rigid-body dynamics）基础上，使用 **残差建模（residual models）** 或 **神经网络修正**，补偿未建模的动力学效应。
- 需要一定量的真实数据（比低数据方法更多，但远少于全建模）。

***实现方式***

- **Residual physics models**：对仿真器中的动力学方程加上残差项，由神经网络学习误差分布。
$$f_{\text{real}}(x,u) \approx f_{\text{sim}}(x,u) + \Delta f_\theta(x,u)$$
- **Neural augmentations of simulators**：将神经网络直接嵌入物理引擎，用于建模关节摩擦、死区、延迟等。
- **SimGAN**：使用生成对抗训练识别并修正仿真参数。

这种方法在鲁棒性和数据量之间取得平衡，但仍需要一定的真实交互。

***评价***：



# 三、高数据方法

***核心思想***
- 基本不依赖物理先验，而是通过大量真实交互数据来 **直接学习全动力学模型**。
- 代价是数据量巨大，训练开销大，但可以最大限度减少建模假设。

***实现方式***
- **DayDreamer**：通过从零开始学习世界模型（world model），结合仿真初始化和真实数据滚动更新。
- **Offline world models**：先在仿真中预训练动力学，再用真实数据微调。
- **Grounded forward/inverse dynamics estimation**：直接拟合真实系统的正向/逆向动力学函数，以增强仿真精度。

这类方法数据和算力消耗非常高，但理论上能够覆盖更多复杂非线性效应。


# 四、在线自适应方法

***核心思想***：

认为再好的离线仿真建模都会有残差，因此在实际部署时，使用 **在线调整机制** 动态补偿 sim-to-real gap

***实现方式***

- **Online fine-tuning**：在真实机器人上边执行边调整策略 [10]。
- **Meta-learning**：预先训练一个“快速适应”的策略，使其在现实少量数据下即可快速收敛。
- **Student–teacher schemes**：教师网络拥有更多状态信息（privileged information），在线训练学生网络，逐步适配真实情况。

## 1. 在线微调（Online Fine-tuning）

- **实现思路**：在实际机器人部署时，继续使用真实环境中的采样数据对策略进行梯度更新。
- **代表方法**：
    - 在 RL 训练好基础策略后，部署到实机时不断采集真实 rollouts，再用 **policy gradient** 或 **actor-critic** 方法进行小步更新。
    - 类似 DayDreamer 这样的世界模型方法也可以在线不断更新系统动力学参数。
- **优点**：能够逐渐适应硬件特性或环境变化。
- **缺点**：需要实机频繁训练，存在安全性和效率问题。


---

## 2. 元学习快速适应（Meta-learning for Rapid Adaptation）

- **实现思路**：在模拟训练阶段，让策略具备“快速适应能力”，一旦遇到真实差异，可以在极少数据下完成调整。
- **代表方法**：
    - MAML（Model-Agnostic Meta Learning）：在仿真中训练时不断变化系统参数，使策略学会在**少量梯度更新**后快速适应不同环境。
    - RL²：使用 RNN 记忆过去交互，从而在新环境中快速收敛。
- **优点**：减少真实数据需求，适合多平台迁移。
- **缺点**：元训练过程复杂，且依赖大规模多样化任务。

## 3. 在线参数辨识（Student–Teacher Schemes / Online SysID）

- **实现思路**：在实机运行时，实时更新系统动力学模型或部分关键参数，并将结果反馈给策略执行。
- **代表方法**：
    - Student–Teacher 框架：teacher 模型不断在线估计物理参数（如摩擦、惯量），student 策略基于 teacher 的输出调整控制。
    - Online SysID：实时根据传感器数据更新简化动力学模型（如延迟、摩擦系数），再由策略利用更新后的模型决策。
- **优点**：相比完全黑箱更新，更具可解释性，参数可直接物理解释。
- **缺点**：依赖辨识精度，复杂情况下可能失败。


---
# 五、总结对比

- **低数据方法**：依赖随机化，数据需求少，泛化性强，但效率低、能耗高。
- **中等数据方法**：结合物理模型和残差修正，平衡建模精度和数据需求。
- **高数据方法**：几乎全依赖真实数据，最少物理先验，精度高但成本极高。
- **在线自适应方法**：适配部署中的 residual gap，可与三类方法结合使用。