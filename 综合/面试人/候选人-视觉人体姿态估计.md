
---

# 🧩 人形机器人视觉算法岗位

**候选人面试提纲（30分钟）**  
**适用对象：** 从事姿态估计、动捕重定向、视频人体数据提取的算法工程师候选人  
**目标：** 评估候选人是否具备从人体视频到机器人骨架的完整视觉算法实现能力

---

## 🕐 面试总结构

|阶段|时间|模块|目的|
|---|---|---|---|
|1|5 min|自我介绍与研究概述|了解候选人的整体研究方向、熟悉程度|
|2|10 min|专业算法知识|检查姿态估计核心算法理解|
|3|10 min|项目与迁移思考|评估其对动捕修正、重定向任务的适应能力|
|4|5 min|综合素质与潜力|评估表达、学习与合作潜力|

---

## 🧭 第一阶段：自我介绍与研究背景（5分钟）

**目标**：了解候选人对自己工作的理解和叙述能力。

| 提问                                                           | 参考答案要点                                                         | 评价指标                  |
| ------------------------------------------------------------ | -------------------------------------------------------------- | --------------------- |
| 请你用2分钟介绍一下你最核心的研究方向和技术积累。                                    | - 研究方向清晰（如人体姿态估计、视频生成、动作重建）- 能提炼关键技术点（如 ViTPose, HybrIK, SMPL） | ✦表达逻辑（20%）✦技术聚焦度（20%） |
| 我看你接触的项目中大多数都是 3 个月左右为一个周期且都为核心开发者，可以介绍一下这几个项目的实现过程以及可复用的思路吗 |                                                                |                       |
| 你在最近的项目中主要解决了哪些痛点？                                           | - 能举例：遮挡、畸形、关键点漂移等- 说明解决思路：数据清洗、模型融合、姿态优化                      | ✦问题分析能力（20%）          |


---

## ⚙️ 第二阶段：专业算法与模型理解（10分钟）

### ① OpenPose、DWPose、SMPL 的区别与联系

| 提问                                   | 答案要点                                                                                                                                                                       | 评价指标                  |
| ------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------- |
| 描述一下 SMPL 的参数描述以及 SMPL 的变体           | - **输入参数**：<br>    - $\beta$（shape）：描述体型（如高矮胖瘦）<br>    - $\theta$（pose）：描述姿态（24 个关节的旋转）<br>    - $T$（global translation）：身体在世界中的平移<br>- **输出**：6890 个顶点的三维网格（可用于可视化、动画、重建） |                       |
| 你能解释一下 OpenPose、DWPose、SMPL 的区别和联系吗？ | - **OpenPose**：2D关键点检测（PAF，2D平面）- **DWPose**：全身2D+伪3D关键点检测（带深度）- **SMPL**：3D人体参数化模型（θ, β, mesh）- 三者关系：图像→关键点→3D人体重建                                                        | ✦理解层次（25%）✦结构化表达（15%） |
| 如果从视频中提取人体动作用于机器人重定向，你会如何串联这三者？      | ① 用 DWPose 提取2D/3D关键点序列② 用 HybrIK / SPIN 拟合 SMPL 参数③ 将 SMPL 输出映射到机器人关节                                                                                                     | ✦系统性思维（20%）           |

---

### ② ViTPose、HybrIK、HaMeR、GVHMR 的差异

| 提问                                | 答案要点                                                                                                                     | 评价指标         |
| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------ | ------------ |
| 这四个模型在人体姿态估计中的核心区别是什么？            | **ViTPose**：2D关键点检测（Transformer结构）- **HybrIK**：3D姿态估计（可微逆运动学）- **HaMeR**：手部mesh恢复（MANO参数）- **GVHMR**：时序+全局重力坐标下的motion重建 | ✦技术理解力（25%）  |
| 如果你要实现人形机器人的动作模仿系统，这四个模型你会如何组合使用？ | ① ViTPose/DWPose 提取 2D关键点② HybrIK 得到 3D SMPL参数③ GVHMR 处理全局位移轨迹④ HaMeR 细化手部                                               | ✦应用迁移思维（25%） |
|                                   | 在人体关键点估计中，如何定义和评估 “关键点定位误差”？除了 MSE，还有哪些指标？                                                                               |              |


| **3** | 你在项目中提到 **HaMeR**，它和 HybrIK 的区别是什么？ | 能否区分模型适用范围与数据特性 | HybrIK 针对全身（SMPL），HaMeR 专注手部（MANO 模型），HaMeR 的网络结构更注重手指 mesh 细节与局部形变。 |
| ----- | ----------------------------------- | --------------- | -------------------------------------------------------------------- |

简要介绍一下 Transformer 

| 序号    | 问题                                                     | 重点考察点                                  | 优秀回答要点                                                                   |
| ----- | ------------------------------------------------------ | -------------------------------------- | ------------------------------------------------------------------------ |
| **1** | 你在多个项目中使用了 **ViTPose**，能简单说明它相比 CNN 架构（比如 HRNet）有什么优势？ | 理解 Transformer 在姿态估计中的作用               | ViTPose 通过 **自注意力机制** 建模人体全局依赖关系（如手脚联动），比CNN局部卷积更能捕捉长距离关键点关系。            |
| **4** | 你提到过 **TransUNet**，这个模型为什么比传统U-Net更适合医学影像？             | 对Transformer结构与医学任务的结合理解               | TransUNet 在 U-Net 的编码器部分引入 **Vision Transformer**，获得全局上下文信息，改善边缘模糊与结构细节。 |
| **2** | 如果模型过拟合，除了正则化，你还会如何改进？                                 | 数据增强、dropout、权重衰减、early stopping、标签平滑。 |                                                                          |
| **5** | 了解 VAE 模型吗或者其他的生成模型或者介绍一下 CNN 的变体                      |                                        |                                                                          |




---

### ③ HybrIK 与 ArcFace

|提问|答案要点|评价指标|
|---|---|---|
|HybrIK 和 ArcFace 分别解决什么问题？|- **HybrIK**：人体3D姿态估计（通过混合逆运动学）- **ArcFace**：人脸识别 / 身份embedding提取（通过角度间隔损失）|✦模型分类与理解（20%）|
|在视频生成或数字人驱动中，为什么要使用 ArcFace？|- 保持身份一致性（避免换脸失真）- 通过 embedding 作为 conditioning 输入|✦算法场景理解（20%）|

---

## 🧩 第三阶段：项目与实际迁移能力（10分钟）

### ① 动捕数据修正与重定向

| 提问                                  | 答案要点                                            | 评价指标            |
| ----------------------------------- | ----------------------------------------------- | --------------- |
| 如果动捕数据中出现骨骼漂移或错位，你会如何检测并修正？         | - 通过关节长度约束检测- 使用滑动窗口平滑或卡尔曼滤波- 利用 SMPL 骨长一致性重新优化 | ✦算法实操经验（25%）    |
| 当我们将 SMPL 关键点重定向到人形机器人时，最大的技术挑战是什么？ | - 自由度差异、比例不匹配- IK求解与接触约束- 动作平衡与物理可行性            | ✦问题洞察（25%）      |
| 如何评估一个修正后的姿态是否“物理可行”？               | - 关节限位检查- COM投影在支撑多边形内- 足底接触约束不漂浮               | ✦控制与物理知识结合（25%） |
| 你有什么熟悉的仿真引擎/平台吗，这个平台可以做哪些的任务        |                                                 |                 |

---

### ② 视频人体数据提取

|提问|答案要点|评价指标|
|---|---|---|
|如果我们从长视频中提取用于模仿学习的人体动作，如何筛选高质量片段？|- 使用 scenedetect 分割场景- 计算关键点置信度均值过滤异常帧- 动作连续性检测|✦数据处理思路（25%）|
|如何让长序列动作更加平滑、连贯？|- 时间滤波（卡尔曼 / Savitzky-Golay）- 时序姿态优化- GVHMR 或 transformer-based temporal alignment|✦时序建模理解（25%）|


---

## 🧩 第四阶段：综合素质与潜力（5分钟）

| 提问                               | 答案要点                                                             | 评价指标          |
| -------------------------------- | ---------------------------------------------------------------- | ------------- |
| 如果要你两周内掌握机器人URDF结构并完成动作映射，你会怎么做？ | - 阅读URDF/XML并建立骨架对应表- 分析关节自由度、定义映射矩阵- 在仿真中验证（Mujoco / Isaac Gym） | ✦学习计划性（20%）   |
| **你更偏向研究算法原理还是做系统落地？**           | 能清楚说明动机、目标与个人定位                                                  | ✦职业匹配度（20%）   |
| 你过去最自豪的一个技术突破是什么？                | 看其能否具体讲清“问题—方案—结果—反思”                                            | ✦表达与反思能力（20%） |


---

## 📊 五、评分表模板（供面试官使用）

| 模块          | 权重   | 评价维度             | 分值   | 备注  |
| ----------- | ---- | ---------------- | ---- | --- |
| 专业理解（算法原理）  | 30%  | 理解深度、表达逻辑、术语准确   | /30  |     |
| 实战经验（项目经验）  | 30%  | 解决问题思路、动捕/重定向经验  | /30  |     |
| 工程思维（系统构建）  | 20%  | 能否将算法融入工程流程      | /20  |     |
| 综合能力（学习与表达） | 20%  | 沟通表达、学习潜力、团队协作   | /20  |     |
| **总分**      | 100% | **录用建议：≥80推荐录用** | /100 |     |

是不是要从事和人形机器人相关的任务：
从事姿态估计、动捕重定向、视频人体数据提取的算法工程师候选人  
我们组是全身运控组的核心需求是两点：
能够对人体数据进行提取完成重定向任务
- 能够对原始动捕数据进行修正、优化数据的重定向过程、建立起一套完善的数据流预处理的 pipeline，支持运控的训练，
- 预研：
	- 从视频流中提取人体数据并进行重定向任务
	- 动作生成：多模态数据（语言/控制指令/图像等），生成我们期望的运动轨迹

多久可进行实习/工作


---
